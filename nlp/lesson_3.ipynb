{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ДЗ 3. Embedding word2vec fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Библиотеки и скрипты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26151,
     "status": "ok",
     "timestamp": 1617177000113,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "wWzU9hqUomdU",
    "outputId": "c305e141-95ae-4580-a705-56e6fb186001"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "import re\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем словарные пары\n",
    "def load_word_pairs(filename):\n",
    "    uk_ru_pairs = []\n",
    "    uk_vectors = []\n",
    "    ru_vectors = []\n",
    "    with open(filename, \"r\", encoding='utf8') as inpf:\n",
    "        for line in inpf:\n",
    "            uk, ru = line.rstrip().split(\"\\t\")\n",
    "            if uk not in uk_emb or ru not in ru_emb:\n",
    "                continue\n",
    "            uk_ru_pairs.append((uk, ru))\n",
    "            uk_vectors.append(uk_emb[uk])\n",
    "            ru_vectors.append(ru_emb[ru])\n",
    "    return uk_ru_pairs, np.array(uk_vectors), np.array(ru_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvqrFUS6vVhh"
   },
   "source": [
    "## Пословный машинный перевод!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7RqUeOXxws8y"
   },
   "source": [
    "Напишем простенькую реализацию модели машинного перевода.\n",
    "\n",
    "Идея основана на статье [Word Translation Without Parallel Data](https://arxiv.org/pdf/1710.04087.pdf). У авторов в репозитории еще много интересного: [https://github.com/facebookresearch/MUSE](https://github.com/facebookresearch/MUSE).\n",
    "\n",
    "А мы будем переводить с украинского на русский.\n",
    "\n",
    "![](https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/resources/blue_cat_blue_whale.png)   \n",
    "*синій кіт* vs. *синій кит*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 533797,
     "status": "ok",
     "timestamp": 1617177652467,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "jjPj9FTRry0U"
   },
   "outputs": [],
   "source": [
    "ru_emb = KeyedVectors.load_word2vec_format(\"data/cc.ru.300.vec\")\n",
    "uk_emb = KeyedVectors.load_word2vec_format(\"data/cc.uk.300.vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7rGx4TXWFJ65"
   },
   "source": [
    "Посмотрим на пару серпень-август (являющихся переводом)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1386,
     "status": "ok",
     "timestamp": 1617177676608,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "FkHer36xyh4n",
    "outputId": "e0aa13d6-02ee-4d3d-dbe1-6aad9f3cb802"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('август', 1.0),\n",
       " ('июль', 0.9383153915405273),\n",
       " ('сентябрь', 0.9240028858184814),\n",
       " ('июнь', 0.9222575426101685),\n",
       " ('октябрь', 0.9095538854598999),\n",
       " ('ноябрь', 0.8930036425590515),\n",
       " ('апрель', 0.8729087114334106),\n",
       " ('декабрь', 0.8652557730674744),\n",
       " ('март', 0.8545796275138855),\n",
       " ('февраль', 0.8401416540145874)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_emb.most_similar([ru_emb[\"август\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 824,
     "status": "ok",
     "timestamp": 1617177689947,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "1RSDixWvylEP",
    "outputId": "dc6fda23-f184-49ed-95cf-23f469a3f7c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('серпень', 0.9999999403953552),\n",
       " ('липень', 0.9096440076828003),\n",
       " ('вересень', 0.901697039604187),\n",
       " ('червень', 0.8992519378662109),\n",
       " ('жовтень', 0.8810408711433411),\n",
       " ('листопад', 0.8787633776664734),\n",
       " ('квітень', 0.8592804670333862),\n",
       " ('грудень', 0.8586863279342651),\n",
       " ('травень', 0.8408110737800598),\n",
       " ('лютий', 0.8256431818008423)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uk_emb.most_similar([uk_emb[\"серпень\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 981,
     "status": "ok",
     "timestamp": 1617177697715,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "iwmm3YQ1yl1U",
    "outputId": "8369591e-4e7f-4686-c208-a9bbafbfa1fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Недопустимость', 0.24435284733772278),\n",
       " ('конструктивность', 0.23293080925941467),\n",
       " ('офор', 0.23256804049015045),\n",
       " ('deteydlya', 0.23031717538833618),\n",
       " ('пресечении', 0.22632381319999695),\n",
       " ('одностороннего', 0.22608885169029236),\n",
       " ('подход', 0.2230587601661682),\n",
       " ('иболее', 0.22003726661205292),\n",
       " ('2015Александр', 0.21872764825820923),\n",
       " ('конструктивен', 0.21796566247940063)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_emb.most_similar([uk_emb[\"серпень\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 5510,
     "status": "ok",
     "timestamp": 1617177712013,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "lAsW7oxszE_I"
   },
   "outputs": [],
   "source": [
    "# Загружаем словари\n",
    "uk_ru_train, X_train, Y_train = load_word_pairs(\"data/ukr_rus.train.txt\")\n",
    "uk_ru_test, X_test, Y_test = load_word_pairs(\"data/ukr_rus.test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9z6ts7DC0XmN"
   },
   "source": [
    "### Учим маппинг из одного пространства эмбеддингов в другое\n",
    "\n",
    "У нас есть пары слов, соответствующих друг другу, и их эмбеддинги. Найдем преобразование из одного пространства в другое, чтобы приблизить известные нам слова:\n",
    "\n",
    "$$W^*= \\arg\\min_W ||WX - Y||_F, \\text{где} ||*||_F - \\text{норма Фробениуса}$$\n",
    "\n",
    "Эта функция очень похожа на линейную регрессию (без биаса).\n",
    "\n",
    "**Задание** Реализуйте её - воспользуйтесь `LinearRegression` из sklearn с `fit_intercept=False`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "fraTOQtu1YWI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(fit_intercept=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = LinearRegression(fit_intercept=False)\n",
    "mapping.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PrzRk3ja1b_6"
   },
   "source": [
    "Проверим, куда перейдет `серпень`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Quax6HnF1aON"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('апрель', 0.8541285991668701),\n",
       " ('июнь', 0.8411201238632202),\n",
       " ('март', 0.8396992683410645),\n",
       " ('сентябрь', 0.835986852645874),\n",
       " ('февраль', 0.8329296708106995),\n",
       " ('октябрь', 0.8311845064163208),\n",
       " ('ноябрь', 0.8278922438621521),\n",
       " ('июль', 0.8234528303146362),\n",
       " ('август', 0.8120500445365906),\n",
       " ('декабрь', 0.8039003610610962)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "august = mapping.predict(uk_emb[\"серпень\"].reshape(1, -1))\n",
    "ru_emb.most_similar(august)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ih1GLNZt1nZX"
   },
   "source": [
    "Должно получиться, что в топе содержатся разные месяцы, но август не первый.\n",
    "\n",
    "Будем мерять percision top-k с k = 1, 5, 10.\n",
    "\n",
    "**Задание** Реализуйте следующую функцию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "JnmrLp9y2gNI"
   },
   "outputs": [],
   "source": [
    "def precision(pairs, mapped_vectors, topn=1):\n",
    "    \"\"\"\n",
    "    :args:\n",
    "        pairs = list of right word pairs [(uk_word_0, ru_word_0), ...]\n",
    "        mapped_vectors = list of embeddings after mapping from source embedding space to destination embedding space\n",
    "        topn = the number of nearest neighbours in destination embedding space to choose from\n",
    "    :returns:\n",
    "        precision_val, float number, total number of words for those we can find right translation at top K.\n",
    "    \"\"\"\n",
    "    assert len(pairs) == len(mapped_vectors)\n",
    "    num_matches = 0\n",
    "    for i, (_, ru) in enumerate(pairs):\n",
    "        for k in range(topn):\n",
    "            if pairs[i][1] in ru_emb.most_similar(mapped_vectors[i].reshape(1, -1), topn=topn)[k][0]:\n",
    "                num_matches = num_matches+1\n",
    "                break\n",
    "    precision_val = num_matches / len(pairs)\n",
    "    return precision_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "-1NIvhSH2olG"
   },
   "outputs": [],
   "source": [
    "assert precision([(\"серпень\", \"август\")], august, topn=5) == 0.0\n",
    "assert precision([(\"серпень\", \"август\")], august, topn=9) == 1.0\n",
    "assert precision([(\"серпень\", \"август\")], august, topn=10) == 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "9Ml_w1Tl2r7Y"
   },
   "outputs": [],
   "source": [
    "assert precision(uk_ru_test, X_test) == 0.0\n",
    "assert precision(uk_ru_test, Y_test) == 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "-d9KQHMr2tx8"
   },
   "outputs": [],
   "source": [
    "precision_top1 = precision(uk_ru_test, mapping.predict(X_test), 1)\n",
    "precision_top5 = precision(uk_ru_test, mapping.predict(X_test), 5)\n",
    "\n",
    "assert precision_top1 >= 0.635\n",
    "assert precision_top5 >= 0.813"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JNbDTP502urT"
   },
   "source": [
    "### Улучшаем маппинг\n",
    "\n",
    "Можно показать, что маппинг лучше строить ортогональным:\n",
    "$$W^*= \\arg\\min_W ||WX - Y||_F \\text{, где: } W^TW = I$$\n",
    "\n",
    "Искать его можно через SVD:\n",
    "$$X^TY=U\\Sigma V^T\\text{, singular value decompostion}$$\n",
    "\n",
    "$$W^*=UV^T$$\n",
    "\n",
    "**Задание** Реализуйте эту функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "9de8XZ_F3v53"
   },
   "outputs": [],
   "source": [
    "def learn_transform(X_train, Y_train):\n",
    "    \"\"\" \n",
    "    :returns: W* : float matrix[emb_dim x emb_dim] as defined in formulae above\n",
    "    \"\"\"\n",
    "    XTY = np.matmul(X_train.T, Y_train)\n",
    "    u, s, v = np.linalg.svd(XTY, full_matrices=False)\n",
    "    W = np.matmul(u, v)\n",
    "    \n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "8WeCadzN382y"
   },
   "outputs": [],
   "source": [
    "W = learn_transform(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "p6qaMb0E3-f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('апрель', 0.8237907886505127),\n",
       " ('сентябрь', 0.8049713373184204),\n",
       " ('март', 0.8025654554367065),\n",
       " ('июнь', 0.8021842837333679),\n",
       " ('октябрь', 0.8001736402511597),\n",
       " ('ноябрь', 0.7934484481811523),\n",
       " ('февраль', 0.7914121150970459),\n",
       " ('июль', 0.7908109426498413),\n",
       " ('август', 0.7891016006469727),\n",
       " ('декабрь', 0.7686373591423035)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_emb.most_similar([np.matmul(uk_emb[\"серпень\"], W)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "_Nn58crh4AH0"
   },
   "outputs": [],
   "source": [
    "assert precision(uk_ru_test, np.matmul(X_test, W)) >= 0.653\n",
    "assert precision(uk_ru_test, np.matmul(X_test, W), 5) >= 0.824"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lqgcYk-c4DE5"
   },
   "source": [
    "### Пишем переводчик"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwi70fP6FaAN"
   },
   "source": [
    "Реализуем простой пословный переводчик - для каждого слова будем искать его ближайшего соседа в общем пространстве эмбеддингов. Если слова нет в эмбеддингах - просто копируем его."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "0etAHUks4JOr"
   },
   "outputs": [],
   "source": [
    "with open(\"data/fairy_tale.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    uk_sentences = [line.rstrip().lower() for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "JK_FJGmn4N7V"
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    \"\"\"\n",
    "    :args:\n",
    "        sentence - sentence in Ukrainian (str)\n",
    "    :returns:\n",
    "        translation - sentence in Russian (str)\n",
    "\n",
    "    * find ukrainian embedding for each word in sentence\n",
    "    * transform ukrainian embedding vector\n",
    "    * find nearest russian word and replace\n",
    "    \"\"\"\n",
    "    ru_sentence = ''\n",
    "    reg_exp = r'[^A-Za-z0-9_]'\n",
    "    for word in sentence.split():\n",
    "        try:\n",
    "            ru_word = ru_emb.most_similar([np.matmul(uk_emb[word], W)], topn=1)[0][0]\n",
    "        except:\n",
    "            ru_word = word\n",
    "            \n",
    "        ru_sentence += ru_word + ' '\n",
    "        \n",
    "    return ru_sentence[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "H47pbFyk4P6D"
   },
   "outputs": [],
   "source": [
    "assert translate(\".\") == \".\"\n",
    "assert translate(\"1 , 3\") == \"1 , 3\"\n",
    "assert translate(\"кіт зловив мишу\") == \"кот поймал мышку\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "PAVWK7mE4RYU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src: ﻿лисичка - сестричка і вовк - панібрат\n",
      "dst: ﻿лисичка – сестричка и волк – панібрат\n",
      "\n",
      "src: як була собі лисичка , да й пішла раз до однії баби добувать огню ; ввійшла у хату да й каже : \" добрий день тобі , бабусю !\n",
      "dst: как была себе лисичка , че и пошла раз к однії бабы добувать огня ; вошла во избу че и говорит : \" хороший день тебе , бабушку !\n",
      "\n",
      "src: дай мені огня \" .\n",
      "dst: дай мне огня \" .\n",
      "\n",
      "src: а баба тільки що вийняла із печі пирожок із маком , солодкий , да й положила , щоб він прохолов ; а лисичка се і підгледала , да тілько що баба нахилилась у піч , щоб достать огня , то лисичка зараз ухватила пирожок да і драла з хати , да , біжучи , весь мак із його виїла , а туда сміття наклала .\n",
      "dst: а бабка только что вынула со печи пирожок со маком , сладкий , че и согнула , чтобы он прохолов ; а лисичка ой и підгледала , че токмо что бабка качнулась во печь , чтобы достать огня , то лисичка сейчас ухватила пирожок че и деру со хаты , че , пробежать , весь мак со его виїла , а туда мусора наложила .\n",
      "\n",
      "src: прибігла на поле , аж там пасуть хлопці бичків .\n",
      "dst: прибежала по поле , аж там пасут парни бычков .\n",
      "\n",
      "src: вона і каже їм : \" ей , хлопці !\n",
      "dst: она и говорит им : \" ой , парни !\n",
      "\n",
      "src: проміняйте мені бичка - третячка за маковий пирожок \" .\n",
      "dst: проміняйте мне бычка – третячка за маковый пирожок \" .\n",
      "\n",
      "src: тії согласились ; так вона їм говорить : \" смотріть же , ви не їжте зараз сього пирожка , а тоді уже розломите , як я заведу бичка за могилку ; а то ви його ні за що не розломите \" .\n",
      "dst: ишо поглумиться ; так она им говорит : \" смотріть то , мы не ешьте сейчас сего пирожка , а тогда уже розломите , как мной заведу бычка за могилу ; а то мы его ни за что не розломите \" .\n",
      "\n",
      "src: бачите вже - лисичка таки собі була розумна , що хоть кого да обманить .\n",
      "dst: вижу уже – лисичка таки себе была умная , что хоть кого че обманить .\n",
      "\n",
      "src: тії хлопці так і зробили , а лисичка як зайшла за могилу , да зараз у ліс і повернула , щоб на дорозі не догнали ; прийшла у ліс да і зробила собі санки да й їде .\n",
      "dst: ишо парни так и сделали , а лисичка как зашла за могилу , че сейчас во лес и вернула , чтобы по дороге не погнали ; пришла во лес че и сделала себе санки че и едет .\n",
      "\n",
      "src: коли йде вовчик : \" здорова була , лисичко - сестричко ! \"\n",
      "dst: когда идет вовчик : \" здоровая была , лисичко – сестричка ! \"\n",
      "\n",
      "src: - \" здоров , вовчику - братику ! \"\n",
      "dst: – \" здоровье , вовчику – братику ! \"\n",
      "\n",
      "src: - \" де се ти узяла собі і бичка і санки ? \"\n",
      "dst: – \" куда ой ты взяла себе и бычка и санки ? \"\n",
      "\n",
      "src: - \" е !\n",
      "dst: – \" ьн !\n",
      "\n",
      "src: зробила \" .\n",
      "dst: сделала \" .\n",
      "\n",
      "src: - \" підвези ж і мене \" .\n",
      "dst: – \" підвези же и меня \" .\n",
      "\n",
      "src: - \" е , вовчику !\n",
      "dst: – \" ьн , вовчику !\n",
      "\n",
      "src: не можна \" .\n",
      "dst: не можно \" .\n",
      "\n",
      "src: - \" мені хоть одну ніжку \" .\n",
      "dst: – \" мне хоть одну ножку \" .\n",
      "\n",
      "src: - \" одну можна \" .\n",
      "dst: – \" одну можно \" .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in uk_sentences[:20]:\n",
    "    print(\"src: {}\\ndst: {}\\n\".format(sentence, translate(sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW-3-colab.ipynb",
   "provenance": [
    {
     "file_id": "1o65wrq6RYgWyyMvNP8r9ZknXBniDoXrn",
     "timestamp": 1617176736329
    }
   ]
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Содержание",
   "title_sidebar": "Содержание",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
