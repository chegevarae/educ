{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fuzzy-invalid",
   "metadata": {
    "id": "fuzzy-invalid"
   },
   "source": [
    "# –î–ó 7. –°–≤–µ—Ä—Ç–æ—á–Ω—ã–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-cream",
   "metadata": {
    "id": "corrected-cream"
   },
   "source": [
    "**–ó–∞–¥–∞–Ω–∏–µ**  \n",
    "\n",
    "–ë–µ—Ä–µ–º –æ—Ç—ã–∑—ã–≤—ã –∑–∞ –ª–µ—Ç–æ (–∏–∑ –∞—Ä—Ö–∏–≤–∞ —Å –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º–∏ –∏–ª–∏ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∑–∞–Ω—è—Ç–∏—è).  \n",
    "1. –£—á–∏–º conv —Å–µ—Ç—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏  \n",
    "2. –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å 2-–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞ —Å–µ—Ç–æ—á–µ–∫  \n",
    "2.1 –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å tf.keras.layers.Embedding –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–º–∏ –≤–µ–∫—Ç–æ—Ä–∞–º–∏ –≤–∑—è—Ç—å –∫ –ø—Ä–∏–º–µ—Ä—É —Å https://rusvectores.org/ru/  \n",
    "2.2 –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–ª–æ–π tf.keras.layers.Embedding –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–Ω—É —Ç–æ –µ—Å—Ç—å –≤–∞–º –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞—Ç—å —Å –≤–µ—Å–∞–º–∏)  \n",
    "\n",
    "–°—Ä–∞–≤–Ω–∏—Ç—å –¥–≤–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏ –∏ –∫–æ–≥–¥–∞ tf.keras.layers.Embedding –æ–±—É—á–∞–µ—Ç—Å—è —Å—Ä–∞–∑—É —Å–æ –≤—Å–µ–π —Å–µ—Ç–æ—á–∫–æ–π, —á—Ç–æ –ø–æ–ª—É—á–∏–ª–æ—Å—å –ª—É—á—à–µ.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedded-conjunction",
   "metadata": {
    "id": "embedded-conjunction"
   },
   "source": [
    "## –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±–∑–æ—Ä –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "gentle-satin",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gentle-satin",
    "outputId": "0297beda-1df6-43c6-e942-073519b3658b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stop_words\n",
      "  Downloading stop-words-2018.7.23.tar.gz (31 kB)\n",
      "Building wheels for collected packages: stop-words\n",
      "  Building wheel for stop-words (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for stop-words: filename=stop_words-2018.7.23-py3-none-any.whl size=32911 sha256=5b3949299193d8c892f8d56a90f616dd4f5d263e739028a9cb6d25317bfb158c\n",
      "  Stored in directory: /root/.cache/pip/wheels/fb/86/b2/277b10b1ce9f73ce15059bf6975d4547cc4ec3feeb651978e9\n",
      "Successfully built stop-words\n",
      "Installing collected packages: stop-words\n",
      "Successfully installed stop-words-2018.7.23\n"
     ]
    }
   ],
   "source": [
    "!pip install stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "regulated-paris",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "regulated-paris",
    "outputId": "cf677e23-ee72-473b-e313-6466a306c08b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymorphy2\n",
      "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 55 kB 2.0 MB/s \n",
      "\u001b[?25hCollecting dawg-python>=0.7.1\n",
      "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n",
      "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
      "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8.2 MB 6.6 MB/s \n",
      "\u001b[?25hInstalling collected packages: pymorphy2-dicts-ru, dawg-python, pymorphy2\n",
      "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "HH9lN6FIqUB4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HH9lN6FIqUB4",
    "outputId": "7cad4b9e-4cf2-4760-ea5f-5dc576fefd70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "682c72ce",
   "metadata": {
    "id": "682c72ce"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from string import punctuation\n",
    "from stop_words import get_stop_words\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "083f009e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "id": "083f009e",
    "outputId": "64c76b5a-1178-4f02-a9de-c9bbdc9b0839",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>It just works!</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>–í —Ü–µ–ª–æ–º —É–¥–æ–±–Ω–æ–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ...–∏–∑ –º–∏–Ω—É—Å–æ–≤ —Ö–æ—Ç—è...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω–æ –≤—Å–µ</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>–°—Ç–∞–ª –∑–∞–≤–∏—Å–∞—Ç—å –Ω–∞ 1% —Ä–∞–±–æ—Ç—ã –∞–Ω—Ç–∏–≤–∏—Ä—É—Å–∞. –î–∞–ª—å—à–µ ...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å —É–¥–æ–±–Ω–æ, —Ä–∞–±–æ—Ç–∞–µ—Ç –±—ã—Å—Ç—Ä–æ.</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>–í—Å—ë —É–¥–æ–±–Ω–æ –Ω–æ—Ä–º üëçüëçüëç</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å —É–¥–æ–±–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ.</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>–í—Å–µ —É—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>–£ –º–µ–Ω—è —Ä–∞–±–æ—Ç–∞–µ—Ç –≤—Å–µ —á–µ—Ç–∫–æ. –í –æ—Ç–ª–∏—á–∏–∏ –æ—Ç –±–∞–Ω–∫–æ–º...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å –≤—Å–µ —Ö–æ—Ä–æ—à–æüëç</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                                            Content        Date\n",
       "0       5                                     It just works!  2017-08-14\n",
       "1       4  –í —Ü–µ–ª–æ–º —É–¥–æ–±–Ω–æ–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ...–∏–∑ –º–∏–Ω—É—Å–æ–≤ —Ö–æ—Ç—è...  2017-08-14\n",
       "2       5                                        –û—Ç–ª–∏—á–Ω–æ –≤—Å–µ  2017-08-14\n",
       "3       5  –°—Ç–∞–ª –∑–∞–≤–∏—Å–∞—Ç—å –Ω–∞ 1% —Ä–∞–±–æ—Ç—ã –∞–Ω—Ç–∏–≤–∏—Ä—É—Å–∞. –î–∞–ª—å—à–µ ...  2017-08-14\n",
       "4       5                     –û—á–µ–Ω—å —É–¥–æ–±–Ω–æ, —Ä–∞–±–æ—Ç–∞–µ—Ç –±—ã—Å—Ç—Ä–æ.  2017-08-14\n",
       "5       5                                –í—Å—ë —É–¥–æ–±–Ω–æ –Ω–æ—Ä–º üëçüëçüëç  2017-08-14\n",
       "6       5                          –û—á–µ–Ω—å —É–¥–æ–±–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ.  2017-08-14\n",
       "7       5                                     –í—Å–µ —É—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç  2017-08-14\n",
       "8       5  –£ –º–µ–Ω—è —Ä–∞–±–æ—Ç–∞–µ—Ç –≤—Å–µ —á–µ—Ç–∫–æ. –í –æ—Ç–ª–∏—á–∏–∏ –æ—Ç –±–∞–Ω–∫–æ–º...  2017-08-14\n",
       "9       5                                  –û—á–µ–Ω—å –≤—Å–µ —Ö–æ—Ä–æ—à–æüëç  2017-08-14"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('–æ—Ç–∑—ã–≤—ã –∑–∞ –ª–µ—Ç–æ.xls')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-seattle",
   "metadata": {
    "id": "legislative-seattle"
   },
   "source": [
    "## –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66f4b34d",
   "metadata": {
    "id": "66f4b34d"
   },
   "outputs": [],
   "source": [
    "# –ó–∞–¥–∞–¥–∏–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "max_words = 200\n",
    "max_len = 150\n",
    "num_classes = 1\n",
    "\n",
    "# Training\n",
    "epochs = 20\n",
    "batch_size = 512\n",
    "print_batch_n = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a54019d8",
   "metadata": {
    "id": "a54019d8"
   },
   "outputs": [],
   "source": [
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(punctuation)\n",
    "morpher = MorphAnalyzer()\n",
    "\n",
    "def preprocess_text(txt):\n",
    "    txt = str(txt)\n",
    "    txt = \"\".join(c for c in txt if c not in exclude)\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(\"\\s–Ω–µ\", \"–Ω–µ\", txt)\n",
    "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
    "    return \" \".join(txt)\n",
    "    \n",
    "df['Content'] = df['Content'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bef7b7bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "id": "bef7b7bd",
    "outputId": "86525b05-f91a-4913-ce18-0aa78f6b76ad"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>it just works</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>—Ü–µ–ª–æ–µ —É–¥–æ–±–Ω–æ–Ω–æ–π –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ–∏–∑ –º–∏–Ω—É—Å —Ö–æ—Ç–µ—Ç—å –±–æ–ª—å...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>–æ—Ç–ª–∏—á–Ω–æ</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>–∑–∞–≤–∏—Å–∞—Ç—å 1 —Ä–∞–±–æ—Ç–∞ –∞–Ω—Ç–∏–≤–∏—Ä—É—Å —Ä–∞–Ω–µ–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>—É–¥–æ–±–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å –±—ã—Å—Ç—Ä–æ</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>—É–¥–æ–±–Ω–æ –Ω–æ—Ä–º–∞ üëçüëçüëç</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>—É–¥–æ–±–Ω—ã–π –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>—É—Å—Ç—Ä–∞–∏–≤–∞—Ç—å</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>—Ä–∞–±–æ—Ç–∞—Ç—å —á—ë—Ç–∫–æ –æ—Ç–ª–∏—á–∏–µ –±–∞–Ω–∫–æ–º–∞—Ç –≤–µ—á–Ω–æ –∑–∞–≤–∏—Å–∞—Ç—å...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>—Ö–æ—Ä–æ—à–æüëç</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                                            Content        Date\n",
       "0       5                                      it just works  2017-08-14\n",
       "1       4  —Ü–µ–ª–æ–µ —É–¥–æ–±–Ω–æ–Ω–æ–π –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ–∏–∑ –º–∏–Ω—É—Å —Ö–æ—Ç–µ—Ç—å –±–æ–ª—å...  2017-08-14\n",
       "2       5                                            –æ—Ç–ª–∏—á–Ω–æ  2017-08-14\n",
       "3       5  –∑–∞–≤–∏—Å–∞—Ç—å 1 —Ä–∞–±–æ—Ç–∞ –∞–Ω—Ç–∏–≤–∏—Ä—É—Å —Ä–∞–Ω–µ–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è...  2017-08-14\n",
       "4       5                             —É–¥–æ–±–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å –±—ã—Å—Ç—Ä–æ  2017-08-14\n",
       "5       5                                   —É–¥–æ–±–Ω–æ –Ω–æ—Ä–º–∞ üëçüëçüëç  2017-08-14\n",
       "6       5                                 —É–¥–æ–±–Ω—ã–π –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ  2017-08-14\n",
       "7       5                                         —É—Å—Ç—Ä–∞–∏–≤–∞—Ç—å  2017-08-14\n",
       "8       5  —Ä–∞–±–æ—Ç–∞—Ç—å —á—ë—Ç–∫–æ –æ—Ç–ª–∏—á–∏–µ –±–∞–Ω–∫–æ–º–∞—Ç –≤–µ—á–Ω–æ –∑–∞–≤–∏—Å–∞—Ç—å...  2017-08-14\n",
       "9       5                                            —Ö–æ—Ä–æ—à–æüëç  2017-08-14"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "796880b1",
   "metadata": {
    "id": "796880b1"
   },
   "outputs": [],
   "source": [
    "# –†–∞–∑–¥–µ–ª–∏–º –Ω–∞ —Ç—Ä–µ–π–Ω –∏ —Ç–µ—Å—Ç\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.Content, df.Rating, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2a9a61f",
   "metadata": {
    "id": "b2a9a61f"
   },
   "outputs": [],
   "source": [
    "train_corpus = \" \".join(X_train)\n",
    "train_corpus = train_corpus.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "662ec08e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "662ec08e",
    "outputId": "a40106b7-5da1-43d0-c874-e1ea9ab947d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "tokens = word_tokenize(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92d1674a",
   "metadata": {
    "id": "92d1674a"
   },
   "outputs": [],
   "source": [
    "tokens_filtered = [word for word in tokens if word.isalnum()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c39adf7",
   "metadata": {
    "id": "5c39adf7"
   },
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "dist = FreqDist(tokens_filtered)\n",
    "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f86c2cb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2f86c2cb",
    "outputId": "629a0d3b-91a0-47a2-bf6a-52299bc7a8ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ',\n",
       " '—É–¥–æ–±–Ω–æ',\n",
       " '—Ä–∞–±–æ—Ç–∞—Ç—å',\n",
       " '—É–¥–æ–±–Ω—ã–π',\n",
       " '–æ—Ç–ª–∏—á–Ω–æ',\n",
       " '–Ω—Ä–∞–≤–∏—Ç—å—Å—è',\n",
       " '—Ö–æ—Ä–æ—à–∏–π',\n",
       " '–æ—Ç–ª–∏—á–Ω—ã–π',\n",
       " '—Ç–µ–ª–µ—Ñ–æ–Ω',\n",
       " '—Å—É–ø–µ—Ä']"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_filtered_top[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2aace7c",
   "metadata": {
    "id": "e2aace7c"
   },
   "outputs": [],
   "source": [
    "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7917145a",
   "metadata": {
    "id": "7917145a"
   },
   "outputs": [],
   "source": [
    "def text_to_sequence(text, maxlen):\n",
    "    result = []\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens_filtered = [word for word in tokens if word.isalnum()]\n",
    "    for word in tokens_filtered:\n",
    "        if word in vocabulary:\n",
    "            result.append(vocabulary[word])\n",
    "    padding = [0]*(maxlen-len(result))\n",
    "    return padding + result[-maxlen:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fa04751",
   "metadata": {
    "id": "2fa04751"
   },
   "outputs": [],
   "source": [
    "x_train = np.asarray([text_to_sequence(text, max_len) for text in X_train], dtype=np.int32)\n",
    "x_test = np.asarray([text_to_sequence(text, max_len) for text in X_test], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ae2d181",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ae2d181",
    "outputId": "af4cf2cb-a809-4c2a-9738-e402945de58b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14461, 150)"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f8bbb59",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6f8bbb59",
    "outputId": "ec1cddea-700e-4e35-8fa6-eb7b24825c88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5458e8cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5458e8cc",
    "outputId": "811e1bff-f304-481b-b54c-4f11c8d40995",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  8,  1,  2, 32],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe97e2f7",
   "metadata": {
    "id": "fe97e2f7"
   },
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5421162",
   "metadata": {
    "id": "b5421162"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Bidirectional, LSTM, SpatialDropout1D, concatenate\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Input\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, Flatten, MaxPooling1D\n",
    "from keras.layers import GlobalMaxPool1D, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import TensorBoard \n",
    "from keras.objectives import categorical_crossentropy\n",
    "from keras.callbacks import EarlyStopping \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "Wcqt6vSIzy6_",
   "metadata": {
    "id": "Wcqt6vSIzy6_"
   },
   "outputs": [],
   "source": [
    "y_train = pd.DataFrame(y_train)\n",
    "y_test = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "Y4sNDxx2vfZl",
   "metadata": {
    "id": "Y4sNDxx2vfZl"
   },
   "outputs": [],
   "source": [
    "num_classes = 6\n",
    "y_train = tf.keras.utils.to_categorical(y_train['Rating'], num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test['Rating'], num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "JX6e-Xqoytg_",
   "metadata": {
    "id": "JX6e-Xqoytg_"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
    "model.add(Conv1D(128, 3))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0Xu4ZnqHy9bF",
   "metadata": {
    "id": "0Xu4ZnqHy9bF"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1m_eaRMMzAUm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1m_eaRMMzAUm",
    "outputId": "a04313b6-fd2e-40a9-b1fc-53bfcad03fba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "26/26 [==============================] - 30s 575ms/step - loss: 1.7469 - accuracy: 0.1097 - val_loss: 1.6438 - val_accuracy: 0.1120\n"
     ]
    }
   ],
   "source": [
    "tensorboard=TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
    "early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[tensorboard, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "XmRZ_KFO0TAK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XmRZ_KFO0TAK",
    "outputId": "c40b94b9-ed6c-4a8e-f7ac-6c05f93e2179"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 2s 135ms/step - loss: 1.6555 - accuracy: 0.0979\n",
      "\n",
      "\n",
      "Test score: 1.6554709672927856\n",
      "Test accuracy: 0.09793481975793839\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3LHSaShc004p",
   "metadata": {
    "id": "3LHSaShc004p"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
    "model.add(Conv1D(128, 3))\n",
    "model.add(Bidirectional(LSTM(units=32, return_sequences=True)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5dRzPeFqB80d",
   "metadata": {
    "id": "5dRzPeFqB80d"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9voXvGZYBu4F",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9voXvGZYBu4F",
    "outputId": "24283974-3784-4ad5-90f6-dada217a7c58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "26/26 [==============================] - 47s 1s/step - loss: 1.4270 - accuracy: 0.6158 - val_loss: 1.0900 - val_accuracy: 0.7049\n"
     ]
    }
   ],
   "source": [
    "tensorboard1=TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
    "early_stopping1=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[tensorboard1, early_stopping1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "_I9gi_-gCbRu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_I9gi_-gCbRu",
    "outputId": "0facba7c-6574-436e-da83-6d0a27b4d254"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 5s 372ms/step - loss: 1.0882 - accuracy: 0.7086\n",
      "\n",
      "\n",
      "Test score: 1.0882039070129395\n",
      "Test accuracy: 0.7086156606674194\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-circular",
   "metadata": {
    "id": "powered-circular"
   },
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "several-weapon",
   "metadata": {
    "id": "several-weapon"
   },
   "outputs": [],
   "source": [
    "ru_w2v = KeyedVectors.load_word2vec_format('https://rusvectores.org/static/models/news_upos_cbow_300_2_2017.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "wF4f3WxvDYjz",
   "metadata": {
    "id": "wF4f3WxvDYjz"
   },
   "outputs": [],
   "source": [
    "def code_w2v_txt(txt, max_len = 100):\n",
    "    sent_w2v = []\n",
    "    zero_point = np.zeros(300)\n",
    "    txt = txt.split()\n",
    "   \n",
    "    for i in range(max_len):\n",
    "        try:\n",
    "            word = ru_w2v[txt[i]]\n",
    "        except:\n",
    "            word = zero_point\n",
    "        sent_w2v.append(word)\n",
    "    return np.array(sent_w2v)\n",
    "\n",
    "max_len = 50\n",
    "df['w2v'] = df['Content'].apply(code_w2v_txt, max_len = max_len)\n",
    "del(ru_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "hSXSbj8AD0ny",
   "metadata": {
    "id": "hSXSbj8AD0ny"
   },
   "outputs": [],
   "source": [
    "X = list(df['w2v'].values)\n",
    "X = np.array(X)\n",
    "y = df['Rating'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "AT4NDgZ7EtNq",
   "metadata": {
    "id": "AT4NDgZ7EtNq"
   },
   "outputs": [],
   "source": [
    "# –†–∞–∑–¥–µ–ª–∏–º –Ω–∞ —Ç—Ä–µ–π–Ω –∏ —Ç–µ—Å—Ç\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b6ojuhCyC4Ao",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b6ojuhCyC4Ao",
    "outputId": "109469ac-5849-4a63-e379-a5971ccb7719"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "train_enc_labels = le.fit_transform(y_train) \n",
    "test_enc_labels = le.transform(y_test)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1CXqjRhEHSg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1CXqjRhEHSg",
    "outputId": "1301282f-5e07-4629-97de-8aabf9b91525"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50, 300)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, 50, 300)      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 50, 14)       17248       spatial_dropout1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 14)           0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 14)           0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 28)           0           global_average_pooling1d[0][0]   \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 64)           1856        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 5)            325         dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 19,429\n",
      "Trainable params: 19,429\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(df.Rating.unique())\n",
    "\n",
    "inputs = Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
    "dropout_embeds = SpatialDropout1D(0.05)(inputs)\n",
    "x = Bidirectional(LSTM(units=7, return_sequences=True))(dropout_embeds)\n",
    "pooled_avg_sequences = GlobalAveragePooling1D()(x)\n",
    "pooled_max_sequences = GlobalMaxPooling1D()(x)\n",
    "concated = concatenate([pooled_avg_sequences, pooled_max_sequences])\n",
    "dense_intermediate = Dense(64, activation='elu')(concated)\n",
    "x = Dense(num_classes, activation='sigmoid')(dense_intermediate)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=x)\n",
    "model.summary()\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "xBtWu8KwEOtW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xBtWu8KwEOtW",
    "outputId": "11f16c6d-4544-4ab5-e50b-9284c732f649"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "26/26 [==============================] - 13s 271ms/step - loss: 1.5469 - accuracy: 0.6141 - val_loss: 1.2649 - val_accuracy: 0.7049\n"
     ]
    }
   ],
   "source": [
    "tensorboard=TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
    "early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "\n",
    "history = model.fit(X_train, train_enc_labels,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[tensorboard, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "k476PA4wEUIR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k476PA4wEUIR",
    "outputId": "5a185290-3ee1-4cd1-aa1d-1d2707dd9ef3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194/194 [==============================] - 2s 12ms/step - loss: 1.2631 - accuracy: 0.7086\n",
      "\n",
      "\n",
      "Test score: 1.2631239891052246\n",
      "Test accuracy: 0.7086156606674194\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, test_enc_labels)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3jhIMRKcIN_L",
   "metadata": {
    "id": "3jhIMRKcIN_L"
   },
   "outputs": [],
   "source": [
    "\n",
    "inputs = Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
    "l_cov1= Conv1D(128, 5, activation='relu')(inputs)\n",
    "l_pool1 = MaxPooling1D(2)(l_cov1)\n",
    "l_cov2 =Conv1D(128, 5, activation='relu')(l_pool1)\n",
    "l_pool2 = MaxPooling1D(2)(l_cov2)\n",
    "l_cov3 = Conv1D(128, 5, activation='relu')(l_pool2)\n",
    "l_pool3 = MaxPooling1D(5)(l_cov3)  # global max pooling\n",
    "l_flat = Flatten()(l_pool3)\n",
    "l_dense = Dense(128, activation='relu')(l_flat)\n",
    "preds = Dense(64, activation='softmax')(l_dense)\n",
    "preds = Dense(num_classes, activation='softmax')(l_dense)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=preds)\n",
    "\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "_maFlx1FIhrN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_maFlx1FIhrN",
    "outputId": "dcb294fc-431b-48d9-8874-61e146aa99df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "26/26 [==============================] - 18s 622ms/step - loss: 1.6030 - accuracy: 0.6174 - val_loss: 1.5835 - val_accuracy: 0.7049\n"
     ]
    }
   ],
   "source": [
    "tensorboard=TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
    "early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "\n",
    "history = model.fit(X_train, train_enc_labels,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[tensorboard, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "Rovxg3-iIvWL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rovxg3-iIvWL",
    "outputId": "36448c1a-a698-4011-81e5-576cb75914ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194/194 [==============================] - 3s 16ms/step - loss: 1.5833 - accuracy: 0.7086\n",
      "\n",
      "\n",
      "Test score: 1.5832996368408203\n",
      "Test accuracy: 0.7086156606674194\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, test_enc_labels)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gXyn2Hp0JaDU",
   "metadata": {
    "id": "gXyn2Hp0JaDU"
   },
   "source": [
    "–ó–∞–∫–æ–Ω—á–∏–ª–∞—Å—å –ø–∞–º—è—Ç—å –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ, –Ω–µ –º–æ–≥—É –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –±–æ–ª—å—à–µ –º–æ–¥–µ–ª–µ–π."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lesson_7.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ",
   "title_sidebar": "–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
