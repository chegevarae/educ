{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ДЗ 3. Построение надежных схем валидации решения, оптимизация целевых метрик"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Основное задание:**  \n",
    "\n",
    "Даны выборки для обучения и для тестирования. Задание заключается в том, чтобы попробовать разные способы валидации, проанализировать плюсы / минусы каждой и сделать выводы о том, какой способ валидации наиболее устойчивый в данной задаче. Метрика качества для оценки прогнозов - ROC-AUC, название целевой переменной - IsFraud. Рекомендуется использовать модели градиетного бустинга, реализация любая / гипепараметры любые.  \n",
    "\n",
    "**Внимание!** выборка assignment_2_test.csv - наш аналог лидерборда. Будем моделировать ситуацию отправки решения на лидерборд и сравнить значение метрики на лидерборде и на локальной валидации.  Для других целей использовать выборку запрещено!  \n",
    "\n",
    "**Терминалогия, используемая в задании:**  \n",
    "* обучающая выборка - выборка, которая передается в метод fit / train;\n",
    "* валидационная выборка - выборка, которая получается при Hold-Out на 2 выборки (train, valid);\n",
    "* тестовая выборка - выборка, которая получается при Hold-Out на 3 выборки (train, valid, test);\n",
    "* ЛБ - лидерборд, выборка assignment_2_test.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "from catboost import Pool\n",
    "from catboost.utils import get_roc_curve\n",
    "\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score, GroupKFold\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Подготовим данные**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/assignment_2_train.csv')\n",
    "board = pd.read_csv('./data/assignment_2_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = train.select_dtypes(exclude=[np.object]).columns.to_list()\n",
    "num_train = train[num_features]\n",
    "num_board = board[num_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = num_train.drop('isFraud', axis=1)\n",
    "y_data = num_train['isFraud']\n",
    "X_board = num_board.drop('isFraud', axis=1)\n",
    "y_board = num_board['isFraud']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hold-Out валидация с разбиением"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 1:** сделать Hold-Out валидацию с разбиением, размер которого будет адеквтаным, по вашему мнению; разбиение проводить по id-транзакции (TransactionID), обучать модель градиетного бустинга любой реализации с подбором числа деревьев по early_stopping критерию до достижения сходимости. Оценить качество модели на валидационной выборке, оценить расхождение по сравнению с качеством на обучающей выборке и валидационной выборке. Оценить качество на ЛБ, сравнить с качеством на обучении и валидации. Сделать выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((125999, 379), (125999,), (54001, 379), (54001,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Разобьем выборку\n",
    "X_train, X_valid = train_test_split(X_data, train_size=0.7, shuffle=True, random_state=1)\n",
    "y_train, y_valid = train_test_split(y_data, train_size=0.7, shuffle=True, random_state=1)\n",
    "\n",
    "X_train.shape, y_train.shape,  X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.74944\tvalidation_1-auc:0.74518\n",
      "[20]\tvalidation_0-auc:0.93829\tvalidation_1-auc:0.90790\n",
      "[40]\tvalidation_0-auc:0.95999\tvalidation_1-auc:0.92489\n",
      "[60]\tvalidation_0-auc:0.96989\tvalidation_1-auc:0.93105\n",
      "[80]\tvalidation_0-auc:0.97807\tvalidation_1-auc:0.93606\n",
      "[99]\tvalidation_0-auc:0.98292\tvalidation_1-auc:0.93776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=16, num_parallel_tree=1, random_state=1,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучим модель\n",
    "model = xgb.XGBClassifier(random_state=1)\n",
    "\n",
    "model.fit(X=X_train, y=y_train, \n",
    "          eval_set=[(X_train, y_train), (X_valid, y_valid)], \n",
    "          early_stopping_rounds=20, \n",
    "          eval_metric=\"auc\",\n",
    "          verbose=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC train = 0.982\n",
      "ROC AUC valid = 0.938\n",
      "ROC AUC board = 0.845\n"
     ]
    }
   ],
   "source": [
    "print(f\"ROC AUC train = {round(roc_auc_score(y_train, model.predict_proba(X_train)[:, 1:]), 3)}\")\n",
    "print(f\"ROC AUC valid = {round(roc_auc_score(y_valid, model.predict_proba(X_valid)[:, 1:]), 3)}\")\n",
    "print(f\"ROC AUC board = {round(roc_auc_score(y_board, model.predict_proba(X_board)[:, 1:]), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы:**  \n",
    "* на обучающей и валидационной выборках наблюдается сильное переобучение\n",
    "* на валидационной и лидерборд выборках наблюдается существенный разрыв метрик\n",
    "* валидация с разбиением не является устойчивой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hold-Out валидация с разбиением на 3 выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2:** сделать Hold-Out валидацию с разбиением на 3 выборки, разбиение проводить по id-транзакции (TransactionID), размер каждой выборки подобрать самостоятельно. Повторить процедуру из п.1. для каждой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((108000, 379), (36000, 379), (36000, 379))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Разобьем выборку на 3 выборки\n",
    "X_train, X_valid = train_test_split(X_data, train_size=0.6, shuffle=True, random_state=1)\n",
    "y_train, y_valid = train_test_split(y_data, train_size=0.6, shuffle=True, random_state=1)\n",
    "\n",
    "X_valid, X_test = train_test_split(X_valid, train_size=0.5, shuffle=True, random_state=42)\n",
    "y_valid, y_test = train_test_split(y_valid, train_size=0.5, shuffle=True, random_state=42)\n",
    "\n",
    "X_train.shape, X_valid.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.74289\tvalidation_1-auc:0.72581\n",
      "[20]\tvalidation_0-auc:0.94236\tvalidation_1-auc:0.90305\n",
      "[40]\tvalidation_0-auc:0.96211\tvalidation_1-auc:0.91841\n",
      "[60]\tvalidation_0-auc:0.97264\tvalidation_1-auc:0.92293\n",
      "[80]\tvalidation_0-auc:0.97927\tvalidation_1-auc:0.92805\n",
      "[99]\tvalidation_0-auc:0.98415\tvalidation_1-auc:0.92902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=16, num_parallel_tree=1, random_state=1,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучим модель\n",
    "model = xgb.XGBClassifier(random_state=1)\n",
    "\n",
    "model.fit(X=X_train, y=y_train,\n",
    "          eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "          early_stopping_rounds=20,\n",
    "          eval_metric=\"auc\",\n",
    "          verbose=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC train = 0.984\n",
      "ROC AUC valid = 0.929\n",
      "ROC AUC test  = 0.934\n",
      "ROC AUC board = 0.838\n"
     ]
    }
   ],
   "source": [
    "print(f\"ROC AUC train = {round(roc_auc_score(y_train, model.predict_proba(X_train)[:, 1:]), 3)}\")\n",
    "print(f\"ROC AUC valid = {round(roc_auc_score(y_valid, model.predict_proba(X_valid)[:, 1:]), 3)}\")\n",
    "print(f\"ROC AUC test  = {round(roc_auc_score(y_test, model.predict_proba(X_test)[:, 1:]), 3)}\")\n",
    "print(f\"ROC AUC board = {round(roc_auc_score(y_board, model.predict_proba(X_board)[:, 1:]), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы:** \n",
    "* по-прежнему на первых трех выборках наблючается сильное переобучение\n",
    "* между выборкой лидерборда и другими по-прежнему существенный разрыв\n",
    "* валидация с разбиением на 3 выборки так же не является устойчивой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Доверительный интервал + качество модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3:** построить доверительный интервал на данных из п.2 на основе бутстреп выборок, оценить качество модели на ЛБ относительно полученного доверительного интервала. Сделать выводы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Подготовим функции**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bootstrap_samples(data: np.array, n_samples: int = 1000) -> np.array:\n",
    "    \"\"\"\n",
    "    Создание бутстреп-выборок.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: np.array\n",
    "        Исходная выборка, которая будет использоваться для\n",
    "        создания бутстреп выборок.\n",
    "\n",
    "    n_samples: int, optional, default = 1000\n",
    "        Количество создаваемых бутстреп выборок.\n",
    "        Опциональный параметр, по умолчанию, равен 1000.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bootstrap_idx: np.array\n",
    "        Матрица индексов, для создания бутстреп выборок.\n",
    "\n",
    "    \"\"\"\n",
    "    bootstrap_idx = np.random.randint(\n",
    "        low=0, high=len(data), size=(n_samples, len(data))\n",
    "    )\n",
    "    return bootstrap_idx\n",
    "\n",
    "\n",
    "def create_bootstrap_metrics(y_true: np.array,\n",
    "                             y_pred: np.array,\n",
    "                             metric: callable,\n",
    "                             n_samlpes: int = 1000) -> List[float]:\n",
    "    \"\"\"\n",
    "    Вычисление бутстреп оценок.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true: np.array\n",
    "        Вектор целевой переменной.\n",
    "\n",
    "    y_pred: np.array\n",
    "        Вектор прогнозов.\n",
    "\n",
    "    metric: callable\n",
    "        Функция для вычисления метрики.\n",
    "        Функция должна принимать 2 аргумента: y_true, y_pred.\n",
    "\n",
    "    n_samples: int, optional, default = 1000\n",
    "        Количество создаваемых бутстреп выборок.\n",
    "        Опциональный параметр, по умолчанию, равен 1000.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bootstrap_metrics: List[float]\n",
    "        Список со значениями метрики качества на каждой бустреп выборке.\n",
    "\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "\n",
    "    if isinstance(y_true, pd.Series):\n",
    "        y_true = y_true.values\n",
    "\n",
    "    bootstrap_idx = create_bootstrap_samples(y_true)\n",
    "    for idx in bootstrap_idx:\n",
    "        y_true_bootstrap = y_true[idx]\n",
    "        y_pred_bootstrap = y_pred[idx]\n",
    "\n",
    "        score = metric(y_true_bootstrap, y_pred_bootstrap)\n",
    "        scores.append(score)\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "def calculate_confidence_interval(scores: list, conf_interval: float = 0.95) -> Tuple[float]:\n",
    "    \"\"\"\n",
    "    Вычисление доверительного интервала.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    scores: List[float / int]\n",
    "        Список с оценками изучаемой величины.\n",
    "\n",
    "    conf_interval: float, optional, default = 0.95\n",
    "        Уровень доверия для построения интервала.\n",
    "        Опциональный параметр, по умолчанию, равен 0.95.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    conf_interval: Tuple[float]\n",
    "        Кортеж с границами доверительного интервала.\n",
    "\n",
    "    \"\"\"\n",
    "    left_bound = np.percentile(\n",
    "        scores, ((1 - conf_interval) / 2) * 100\n",
    "    )\n",
    "    right_bound = np.percentile(\n",
    "        scores, (conf_interval + ((1 - conf_interval) / 2)) * 100\n",
    "    )\n",
    "\n",
    "    return left_bound, right_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Оценим качество и построим доверительный интервал**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.837744\n",
       "dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Качество модели\n",
    "np.random.seed(42)\n",
    "scores = create_bootstrap_metrics(y_board, model.predict_proba(X_board)[:, 1:], roc_auc_score)\n",
    "pd.DataFrame(scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8301766452107935, 0.8454514275265516)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Доверительный интервал\n",
    "calculate_confidence_interval(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** метрика находится в пределах доверительного интервала, что говорит об устойчивости валидации на 3 выборках."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Validation + качество модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4:** выполнить Adversarial Validation, подобрать объекты из обучающей выборки, которые сильно похожи на объекты из assignment_2_test.csv, и использовать их в качестве валидационного набора. Оценить качество модели на ЛБ, сделать выводы о полученных результатах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_adv = pd.concat([X_data, X_board], axis=0)\n",
    "y_adv = np.hstack((np.zeros(X_data.shape[0]), np.ones(X_board.shape[0])))\n",
    "\n",
    "assert X_adv.shape[0] == y_adv.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:29:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=42, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучим модель\n",
    "model = xgb.XGBClassifier(n_estimators=42)\n",
    "model.fit(X_adv, y_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred_adv = model.predict_proba(X_adv)\n",
    "score = roc_auc_score(y_adv, y_pred_adv[:, 1])\n",
    "print(round(score, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9999416e-01, 5.8439687e-06],\n",
       "       [9.9999416e-01, 5.8439687e-06],\n",
       "       [9.9999416e-01, 5.8439687e-06],\n",
       "       ...,\n",
       "       [9.9999207e-01, 7.9173988e-06],\n",
       "       [9.9999207e-01, 7.9173988e-06],\n",
       "       [9.9999207e-01, 7.9173988e-06]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_proba(X_data)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.1]    180000\n",
       "(0.1, 0.2]         0\n",
       "(0.2, 0.3]         0\n",
       "(0.3, 0.4]         0\n",
       "(0.4, 0.5]         0\n",
       "(0.5, 0.6]         0\n",
       "(0.6, 0.7]         0\n",
       "(0.7, 0.8]         0\n",
       "(0.8, 0.9]         0\n",
       "(0.9, 1.0]         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.cut(y_pred[:, 1], bins=np.arange(0, 1.01, 0.1)).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** объекты обучаемой выборки похожи на объекты валидационной выборки, значит их можно использовать для обучения модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFold/StratifiedKFold валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 5:** сделать KFold / StratifiedKFold валидацию (на ваше усмотрение), оценить получаемые качество и разброс по метрике качества. Сделать выводы об устойчивости кросс-валидации, сходимости оценки на кросс-валидации и отложенном наборе данных; Оценить качество на ЛБ, сделать выводы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Подготовим функции**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cross_validation(X: pd.DataFrame,\n",
    "                          y: pd.Series,\n",
    "                          estimator: object,\n",
    "                          metric: callable,\n",
    "                          cv_strategy):\n",
    "    \"\"\"\n",
    "    Кросс-валидация.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: pd.DataFrame\n",
    "        Матрица признаков.\n",
    "\n",
    "    y: pd.Series\n",
    "        Вектор целевой переменной.\n",
    "\n",
    "    estimator: callable\n",
    "        Объект модели для обучения.\n",
    "\n",
    "    metric: callable\n",
    "        Метрика для оценки качества решения.\n",
    "        Ожидается, что на вход будет передана функция,\n",
    "        которая принимает 2 аргумента: y_true, y_pred.\n",
    "\n",
    "    cv_strategy: cross-validation generator\n",
    "        Объект для описания стратегии кросс-валидации.\n",
    "        Ожидается, что на вход будет передан объект типа\n",
    "        KFold или StratifiedKFold.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    oof_score: float\n",
    "        Значение метрики качества на OOF-прогнозах.\n",
    "\n",
    "    fold_train_scores: List[float]\n",
    "        Значение метрики качества на каждом обучающем датасете кросс-валидации.\n",
    "\n",
    "    fold_valid_scores: List[float]\n",
    "        Значение метрики качества на каждом валидационном датасете кросс-валидации.\n",
    "\n",
    "    oof_predictions: np.array\n",
    "        Прогнозы на OOF.\n",
    "\n",
    "    \"\"\"\n",
    "    estimators, fold_train_scores, fold_valid_scores = [], [], []\n",
    "    oof_predictions = np.zeros(X.shape[0])\n",
    "\n",
    "    for fold_number, (train_idx, valid_idx) in enumerate(cv_strategy.split(X, y)):\n",
    "        x_train, x_valid = X.loc[train_idx], X.loc[valid_idx]\n",
    "        y_train, y_valid = y.loc[train_idx], y.loc[valid_idx]\n",
    "\n",
    "        estimator.fit(x_train, y_train)\n",
    "        y_train_pred = estimator.predict(x_train)\n",
    "        y_valid_pred = estimator.predict(x_valid)\n",
    "\n",
    "        fold_train_scores.append(metric(y_train, y_train_pred))\n",
    "        fold_valid_scores.append(metric(y_valid, y_valid_pred))\n",
    "        oof_predictions[valid_idx] = y_valid_pred\n",
    "\n",
    "        msg = (\n",
    "            f\"Fold: {fold_number+1}, train-observations = {len(train_idx)}, \"\n",
    "            f\"valid-observations = {len(valid_idx)}\\n\"\n",
    "            f\"train-score = {round(fold_train_scores[fold_number], 4)}, \"\n",
    "            f\"valid-score = {round(fold_valid_scores[fold_number], 4)}\" \n",
    "        )\n",
    "        print(msg)\n",
    "        print(\"=\"*69)\n",
    "        estimators.append(estimator)\n",
    "\n",
    "    oof_score = metric(y, oof_predictions)\n",
    "    print(f\"CV-results train: {round(np.mean(fold_train_scores), 4)} +/- {round(np.std(fold_train_scores), 3)}\")\n",
    "    print(f\"CV-results valid: {round(np.mean(fold_valid_scores), 4)} +/- {round(np.std(fold_valid_scores), 3)}\")\n",
    "    print(f\"OOF-score = {round(oof_score, 4)}\")\n",
    "\n",
    "    return estimators, oof_score, fold_train_scores, fold_valid_scores, oof_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:34:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold: 1, train-observations = 144000, valid-observations = 36000\n",
      "train-score = 0.7744, valid-score = 0.6374\n",
      "=====================================================================\n",
      "[20:34:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold: 2, train-observations = 144000, valid-observations = 36000\n",
      "train-score = 0.7749, valid-score = 0.6651\n",
      "=====================================================================\n",
      "[20:34:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold: 3, train-observations = 144000, valid-observations = 36000\n",
      "train-score = 0.7601, valid-score = 0.7046\n",
      "=====================================================================\n",
      "[20:34:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold: 4, train-observations = 144000, valid-observations = 36000\n",
      "train-score = 0.7707, valid-score = 0.6778\n",
      "=====================================================================\n",
      "[20:35:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold: 5, train-observations = 144000, valid-observations = 36000\n",
      "train-score = 0.7672, valid-score = 0.6794\n",
      "=====================================================================\n",
      "CV-results train: 0.7695 +/- 0.005\n",
      "CV-results valid: 0.6728 +/- 0.022\n",
      "OOF-score = 0.6718\n"
     ]
    }
   ],
   "source": [
    "cv_strategy = KFold(n_splits=5)\n",
    "estimators, oof_score, fold_train_scores, fold_valid_scores, oof_predictions = make_cross_validation(X_data, y_data, \n",
    "                                                                                                     model, \n",
    "                                                                                                     metric=roc_auc_score, \n",
    "                                                                                                     cv_strategy=cv_strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:36:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold: 1, train-observations = 80000, valid-observations = 20001\n",
      "train-score = 0.777, valid-score = 0.67\n",
      "=====================================================================\n",
      "[20:36:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold: 2, train-observations = 80001, valid-observations = 20000\n",
      "train-score = 0.7827, valid-score = 0.6401\n",
      "=====================================================================\n",
      "[20:36:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold: 3, train-observations = 80001, valid-observations = 20000\n",
      "train-score = 0.7764, valid-score = 0.6387\n",
      "=====================================================================\n",
      "[20:36:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold: 4, train-observations = 80001, valid-observations = 20000\n",
      "train-score = 0.776, valid-score = 0.6839\n",
      "=====================================================================\n",
      "[20:37:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold: 5, train-observations = 80001, valid-observations = 20000\n",
      "train-score = 0.7799, valid-score = 0.7276\n",
      "=====================================================================\n",
      "CV-results train: 0.7784 +/- 0.003\n",
      "CV-results valid: 0.672 +/- 0.033\n",
      "OOF-score = 0.6768\n"
     ]
    }
   ],
   "source": [
    "cv_strategy = KFold(n_splits=5)\n",
    "estimators, oof_score, fold_train_scores, fold_valid_scores, oof_predictions = make_cross_validation(X_board, y_board, \n",
    "                                                                                                     model, \n",
    "                                                                                                     metric=roc_auc_score, \n",
    "                                                                                                     cv_strategy=cv_strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** наблюдаем не очень большую дисперсии на основании результатов обучающей и лидерборд выборок, можем утверждать, что KFold валидация является достаточно устойчивой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hold-Out валидацию по времени"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 6 (опциональное):** сделать Hold-Out валидацию по времени (TransactionDT), повторить процедуры из п.1 / п.2 (на ваш выбор). Построить доверительный интервал, сравнить качество на ЛБ выборке с полученным доверительным интервалом. Сделать выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150000, 379), (30000, 379), (150000,), (30000,))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = TimeSeriesSplit()\n",
    "\n",
    "for train_index, test_index in cv.split(X_data):\n",
    "    X_train, X_valid = X_data.loc[train_index], X_data.loc[test_index]\n",
    "    y_train, y_valid = y_data[train_index], y_data[test_index]\n",
    "    \n",
    "X_train.shape,  X_valid.shape, y_train.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.76162\tvalidation_1-auc:0.75636\n",
      "[20]\tvalidation_0-auc:0.93785\tvalidation_1-auc:0.89197\n",
      "[40]\tvalidation_0-auc:0.95839\tvalidation_1-auc:0.90488\n",
      "[60]\tvalidation_0-auc:0.96540\tvalidation_1-auc:0.90367\n",
      "[62]\tvalidation_0-auc:0.96578\tvalidation_1-auc:0.90387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=16, num_parallel_tree=1, random_state=1,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(random_state=1)\n",
    "\n",
    "model.fit(X=X_train, y=y_train,\n",
    "          eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "          early_stopping_rounds=20,\n",
    "          eval_metric=\"auc\",\n",
    "          verbose=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC train = 0.959\n",
      "ROC AUC valid = 0.906\n",
      "ROC AUC board = 0.853\n"
     ]
    }
   ],
   "source": [
    "print(f\"ROC AUC train = {round(roc_auc_score(y_train, model.predict_proba(X_train)[:, 1:]), 3)}\")\n",
    "print(f\"ROC AUC valid = {round(roc_auc_score(y_valid, model.predict_proba(X_valid)[:, 1:]), 3)}\")\n",
    "print(f\"ROC AUC board = {round(roc_auc_score(y_board, model.predict_proba(X_board)[:, 1:]), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.853181\n",
       "dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Качество модели\n",
    "np.random.seed(42)\n",
    "scores = create_bootstrap_metrics(y_board, model.predict_proba(X_board)[:, 1:], roc_auc_score)\n",
    "pd.DataFrame(scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8462826718303791, 0.8603543072426955)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Доверительный интервал\n",
    "calculate_confidence_interval(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** метрика выборки лидерборда входит в доверительный интервал, но ее нельзя назвать устойчивой, т.к. наблюдается значимый разрыв между метриками обучающей и лидерборд выборок."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GroupKFold валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 7 (совсем опциональное):** в данном наборе данных у нас есть ID-транзакции (TransactionID) и время транзакции (TransactionDT), но отсутствует ID-клиента, который совершал транзакции. Кажется, что в этой задаче валидация по клиенту работала бы хорошо. Предложить критерий, по которому можно выделить клиентов и сделать п.5, используя созданное определение клиента, используя валидацию по клиенту (GroupKFold)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Подготовим функции**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clientID(data):\n",
    "    \n",
    "    for n, k in enumerate(data['ProductCD'].value_counts().keys()):\n",
    "        data.loc[data['ProductCD'] == k, 'ProdCD'] = n\n",
    "    data['ProdCD'] = data['ProdCD'].astype(np.int8)\n",
    "\n",
    "    data.loc[data['P_emaildomain'].isnull(), 'P_emaildomain'] = 'nan'\n",
    "    for n, k in enumerate(data['P_emaildomain'].value_counts().keys()):\n",
    "        data.loc[data['P_emaildomain'] == k, 'P_email'] = n\n",
    "    data['P_email'] = data['P_email'].astype(np.int8)\n",
    "\n",
    "    data['ClientID'] = data['ProdCD'].astype(str) + data['card1'].astype(str) + data['P_email'].astype(str)\n",
    "    data['ClientID'] = data['ClientID'].astype(np.int32)\n",
    "\n",
    "    data = data.drop(['ProdCD', 'P_email'], axis=1)\n",
    "    \n",
    "    num_features = data.select_dtypes(exclude=[np.object]).columns.to_list()\n",
    "    data_num = data[num_features]\n",
    "    \n",
    "    X_data = data_num.drop('isFraud', axis=1)\n",
    "    y_data = data_num['isFraud']\n",
    "    \n",
    "    return X_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, y_data = get_clientID(train)\n",
    "X_board, y_board = get_clientID(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cross_validation_groups(X: pd.DataFrame,\n",
    "                              y: pd.Series,\n",
    "                              estimator: object,\n",
    "                              metric: callable,\n",
    "                              cv_strategy,\n",
    "                              groups):\n",
    "\n",
    "    estimators, fold_train_scores, fold_valid_scores = [], [], []\n",
    "    oof_predictions = np.zeros(X.shape[0])\n",
    "\n",
    "    for fold_number, (train_idx, valid_idx) in enumerate(cv_strategy.split(X, y, groups=X[groups])):\n",
    "        x_train, x_valid = X.loc[train_idx], X.loc[valid_idx]\n",
    "        y_train, y_valid = y.loc[train_idx], y.loc[valid_idx]\n",
    "\n",
    "        estimator.fit(x_train, y_train)\n",
    "        y_train_pred = estimator.predict(x_train)\n",
    "        y_valid_pred = estimator.predict(x_valid)\n",
    "\n",
    "        fold_train_scores.append(metric(y_train, y_train_pred))\n",
    "        fold_valid_scores.append(metric(y_valid, y_valid_pred))\n",
    "        oof_predictions[valid_idx] = y_valid_pred\n",
    "\n",
    "        msg = (\n",
    "            f\"Fold: {fold_number+1}, train-observations = {len(train_idx)}, \"\n",
    "            f\"valid-observations = {len(valid_idx)}\\n\"\n",
    "            f\"train-score = {round(fold_train_scores[fold_number], 4)}, \"\n",
    "            f\"valid-score = {round(fold_valid_scores[fold_number], 4)}\" \n",
    "        )\n",
    "        print(msg)\n",
    "        print(\"=\"*69)\n",
    "        estimators.append(estimator)\n",
    "\n",
    "    oof_score = metric(y, oof_predictions)\n",
    "    print(f\"CV-results train: {round(np.mean(fold_train_scores), 4)} +/- {round(np.std(fold_train_scores), 3)}\")\n",
    "    print(f\"CV-results valid: {round(np.mean(fold_valid_scores), 4)} +/- {round(np.std(fold_valid_scores), 3)}\")\n",
    "    print(f\"OOF-score = {round(oof_score, 4)}\")\n",
    "\n",
    "    return estimators, oof_score, fold_train_scores, fold_valid_scores, oof_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:47:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold: 1, train-observations = 144000, valid-observations = 36000\n",
      "train-score = 0.7775, valid-score = 0.6726\n",
      "=====================================================================\n",
      "[20:48:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold: 2, train-observations = 144000, valid-observations = 36000\n",
      "train-score = 0.7696, valid-score = 0.6511\n",
      "=====================================================================\n",
      "[20:48:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold: 3, train-observations = 144000, valid-observations = 36000\n",
      "train-score = 0.7743, valid-score = 0.7012\n",
      "=====================================================================\n",
      "[20:48:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold: 4, train-observations = 144000, valid-observations = 36000\n",
      "train-score = 0.7739, valid-score = 0.6545\n",
      "=====================================================================\n",
      "[20:49:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold: 5, train-observations = 144000, valid-observations = 36000\n",
      "train-score = 0.7758, valid-score = 0.6332\n",
      "=====================================================================\n",
      "CV-results train: 0.7742 +/- 0.003\n",
      "CV-results valid: 0.6625 +/- 0.023\n",
      "OOF-score = 0.6636\n"
     ]
    }
   ],
   "source": [
    "cv_strategy = GroupKFold(n_splits=5)\n",
    "estimators, oof_score, fold_train_scores, \n",
    "fold_valid_scores, oof_predictions = make_cross_validation_groups(X_data, y_data,\n",
    "                                                                  model, \n",
    "                                                                  metric=roc_auc_score, \n",
    "                                                                  cv_strategy=cv_strategy, \n",
    "                                                                  groups='ClientID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:51:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold: 1, train-observations = 80000, valid-observations = 20001\n",
      "train-score = 0.7816, valid-score = 0.6911\n",
      "=====================================================================\n",
      "[20:51:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold: 2, train-observations = 80001, valid-observations = 20000\n",
      "train-score = 0.7808, valid-score = 0.6365\n",
      "=====================================================================\n",
      "[20:51:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold: 3, train-observations = 80001, valid-observations = 20000\n",
      "train-score = 0.7829, valid-score = 0.6771\n",
      "=====================================================================\n",
      "[20:51:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold: 4, train-observations = 80001, valid-observations = 20000\n",
      "train-score = 0.7918, valid-score = 0.6602\n",
      "=====================================================================\n",
      "[20:51:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold: 5, train-observations = 80001, valid-observations = 20000\n",
      "train-score = 0.7832, valid-score = 0.6522\n",
      "=====================================================================\n",
      "CV-results train: 0.7841 +/- 0.004\n",
      "CV-results valid: 0.6634 +/- 0.019\n",
      "OOF-score = 0.6643\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-e8bf838c520f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                                                   \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                                                                   \u001b[0mcv_strategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv_strategy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                                                                   groups='ClientID')\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "cv_strategy = GroupKFold(n_splits=5)\n",
    "estimators, oof_score, fold_train_scores, \n",
    "fold_valid_scores, oof_predictions = make_cross_validation_groups(X_board, y_board, \n",
    "                                                                  model, \n",
    "                                                                  metric=roc_auc_score, \n",
    "                                                                  cv_strategy=cv_strategy, \n",
    "                                                                  groups='ClientID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** судя по метрике валидация GroupKFold по предположительному клиенту является стабильной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Содержание",
   "title_sidebar": "Содержание",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.091px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
