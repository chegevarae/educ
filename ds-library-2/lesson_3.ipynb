{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ДЗ 3. Построение модели классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики качества классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для чего и в каких случаях полезны различные варианты усреднения для метрик качества классификации: micro, macro, weighted?  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные метрики необходимы в тех случаях, когда мы используем больше 2-ух классов в наших моделях, т.е. они необходимы нам для понимания насколько хорошо мы предсказываем результат. Другими словами, они позволяют получить одну общую цифру для всех классов.  \n",
    "\n",
    "**MICRO**  \n",
    "Параметр average MICRO для f1-score равен accuracy, который позволяет получить долю правильных ответов во всей выборке.  \n",
    "\n",
    "**MACRO**  \n",
    "Параметр average MACRO для f1-score, который позволяет получить арифметическое среднее значение для каждого класса.  \n",
    "Помимо этого при больших значениях MACRO мы понимаем, что модель переобучилась.  \n",
    "\n",
    "**WEIGHTED**  \n",
    "Параметр average WEIGHTED для f1-score, который позволяет получить взвешенное среднее значение частоты класса для каждого класса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модели xgboost, lightgbm и catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В чём разница между моделями xgboost, lightgbm и catboost или какие их основные особенности?  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все три модели это разновидности градиентного бустинга.  \n",
    "\n",
    "**Особенности XGBoost**  \n",
    "\n",
    "Вместо энтропии или критерия Джимми подсчитывается \"Похожесть\", т.е. насколько в рамках одной вершины/листа находятся одинаковые объекты, насколько они между собою похожи.  \n",
    "Также иначе считается прирост информации.  \n",
    "После построения дерева начинается его стрижка в зависимости от величины прироста.  \n",
    "Основные параметры: регуляризация, минимальный прирост и скорость обучения.  \n",
    "\n",
    "**Особенности LightGBM**  \n",
    "\n",
    "Облегченная модель бустинга, которая обучается гораздо быстрее за счет того, что для обучения берется только часть выборки.  Существует 2 основных метода:  \n",
    "\n",
    "_Gradient-based One-Side Sampling (GOSS)_  \n",
    "GOSS сохраняет наблюдения с большим градиентом и случайно сэмплирует выборку из наблюдений с маленькими градиентами.  \n",
    "Итого, выбирается a * 100% наблюдений из топа с большими градиентами.  \n",
    "Рандомно b * 100% наблюдений из остальной.   \n",
    "\n",
    "_Exclusive Feature Bundling (EFB)_  \n",
    "Разряженные данные значат, что многие признаки заменены нулями. Это позволяет совместить (\"bundle\") эти фичи в одну без потери информации.  \n",
    "Пример, у фичи А диапазон значений (0, 10) и у B - (0, 20). Добавляется смещение 10 к значениям фичи B, теперь их диапазон (10, 30). После, можно соединять A и B и использовать \"feature bundle\" с диапазоном (0, 30), чтобы заменить оригинальные A и B.  \n",
    "\n",
    "\n",
    "**Особенности CatBoost**  \n",
    "\n",
    "- Деревья симметричны, что предотвращает переобучение  \n",
    "-- Обучается несколько моделей за одну итерацию и высчитываются остатки по наблюдениям на тех моделях, которые не видели его  \n",
    "-- Высокий уровень рандома (перемешивание выборки и много случайности в начале построения дерева)  \n",
    "- Автоматическая работа с категориальными признаками и переобучением"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
