{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "capable-killing",
   "metadata": {},
   "source": [
    "# ДЗ 2. Профилирование пользователей. Сегментация аудитории: unsupervised learning (clustering, LDA/ARTM), supervised (multi/binary classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-delight",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "silver-emerald",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from razdel import tokenize\n",
    "import pymorphy2\n",
    "\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, classification_report, \\\n",
    "                                precision_recall_curve, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "theoretical-restriction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>Заместитель председателяnправительства РФnСерг...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4896</td>\n",
       "      <td>Матч 1/16 финала Кубка России по футболу был п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4897</td>\n",
       "      <td>Форвард «Авангарда» Томаш Заборский прокоммент...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id                                              title\n",
       "0       6  Заместитель председателяnправительства РФnСерг...\n",
       "1    4896  Матч 1/16 финала Кубка России по футболу был п...\n",
       "2    4897  Форвард «Авангарда» Томаш Заборский прокоммент..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = pd.read_csv(\"data/articles.csv\")\n",
    "print(news.shape)\n",
    "news.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "central-brazilian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u105138</td>\n",
       "      <td>[293672, 293328, 293001, 293622, 293126, 1852]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u108690</td>\n",
       "      <td>[3405, 1739, 2972, 1158, 1599, 322665]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u108339</td>\n",
       "      <td>[1845, 2009, 2356, 1424, 2939, 323389]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid                                        articles\n",
       "0  u105138  [293672, 293328, 293001, 293622, 293126, 1852]\n",
       "1  u108690          [3405, 1739, 2972, 1158, 1599, 322665]\n",
       "2  u108339          [1845, 2009, 2356, 1424, 2939, 323389]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = pd.read_csv(\"data/users_articles.csv\")\n",
    "print(users.shape)\n",
    "users.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "monthly-vulnerability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u107120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u102277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u102444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid  churn\n",
       "0  u107120      0\n",
       "1  u102277      0\n",
       "2  u102444      0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = pd.read_csv(\"data/users_churn.csv\")\n",
    "print(target.shape)\n",
    "target.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "interstate-calvin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopword_ru = stopwords.words('russian')\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "with open('data/stopwords.txt') as f:\n",
    "    additional_stopwords = [w.strip() for w in f.readlines() if w]\n",
    "stopword_ru += additional_stopwords\n",
    "len(stopword_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "danish-america",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''\n",
    "    очистка текста\n",
    "    \n",
    "    на выходе очищеный текст\n",
    "    \n",
    "    '''\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = text.strip('\\n').strip('\\r').strip('\\t')\n",
    "    text = re.sub(\"-\\s\\r\\n\\|-\\s\\r\\n|\\r\\n\", '', str(text))\n",
    "\n",
    "    text = re.sub(\"[0-9]|[-—.,:;_%©«»?*!@#№$^•·&()]|[+=]|[[]|[]]|[/]|\", '', text)\n",
    "    text = re.sub(r\"\\r\\n\\t|\\n|\\\\s|\\r\\t|\\\\n\", ' ', text)\n",
    "    text = re.sub(r'[\\xad]|[\\s+]', ' ', text.strip())\n",
    "    \n",
    "    #tokens = list(tokenize(text))\n",
    "    #words = [_.text for _ in tokens]\n",
    "    #words = [w for w in words if w not in stopword_ru]\n",
    "    \n",
    "    #return \" \".join(words)\n",
    "    return text\n",
    "\n",
    "cache = {}\n",
    "\n",
    "def lemmatization(text):\n",
    "    '''\n",
    "    лемматизация\n",
    "        [0] если зашел тип не `str` делаем его `str`\n",
    "        [1] токенизация предложения через razdel\n",
    "        [2] проверка есть ли в начале слова '-'\n",
    "        [3] проверка токена с одного символа\n",
    "        [4] проверка есть ли данное слово в кэше\n",
    "        [5] лемматизация слова\n",
    "        [6] проверка на стоп-слова\n",
    "\n",
    "    на выходе лист отлемматизированых токенов\n",
    "    '''\n",
    "\n",
    "    # [0]\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \n",
    "    # [1]\n",
    "    tokens = list(tokenize(text))\n",
    "    words = [_.text for _ in tokens]\n",
    "\n",
    "    words_lem = []\n",
    "    for w in words:\n",
    "        if w[0] == '-': # [2]\n",
    "            w = w[1:]\n",
    "        if len(w)>1: # [3]\n",
    "            if w in cache: # [4]\n",
    "                words_lem.append(cache[w])\n",
    "            else: # [5]\n",
    "                temp_cach = cache[w] = morph.parse(w)[0].normal_form\n",
    "                words_lem.append(temp_cach)\n",
    "    \n",
    "    words_lem_without_stopwords=[i for i in words_lem if not i in stopword_ru] # [6]\n",
    "    \n",
    "    return words_lem_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "unauthorized-california",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vlad\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:15: FutureWarning: Possible nested set at position 39\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Запускаем очистку текста. Будет долго...\n",
    "news['title'] = news['title'].apply(lambda x: clean_text(x), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "seasonal-maine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Запускаем лемматизацию текста. Будет очень долго...\n",
    "news['title'] = news['title'].apply(lambda x: lemmatization(x), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "pressing-taiwan",
   "metadata": {},
   "outputs": [],
   "source": [
    "#сформируем список наших текстов, разбив еще и на пробелы\n",
    "texts = [t for t in news['title'].values]\n",
    "\n",
    "# Create a corpus from a list of texts\n",
    "common_dictionary = Dictionary(texts)\n",
    "common_corpus = [common_dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fiscal-andorra",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запускаем обучение\n",
    "lda = LdaModel(common_corpus, num_topics=25, id2word=common_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "loaded-craft",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['форвард', 'авангард', 'томаш', 'заборский', 'прокомментировать', 'игра', 'свой', 'команда', 'матч', 'чемпионат', 'кхл', 'против', 'атланта', 'nnnn', 'провести', 'плохой', 'матч', 'нижний', 'новгород', 'против', 'торпедо', 'настраиваться', 'первый', 'минута', 'включиться', 'работа', 'сказать', 'заборский', 'получиться', 'забросить', 'быстрый', 'гол', 'задать', 'хороший', 'темп', 'поединок', 'мочь', 'играть', 'ещё', 'хороший', 'сторона', 'пять', 'очко', 'выезд', 'девять', 'это', 'хороший']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(3, 0.2730403), (7, 0.2724014), (11, 0.31866744), (19, 0.11672639)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new corpus, made of previously unseen documents.\n",
    "other_texts = [t for t in news['title'].iloc[:3]]\n",
    "other_corpus = [common_dictionary.doc2bow(text) for text in other_texts]\n",
    "\n",
    "unseen_doc = other_corpus[2]\n",
    "print(other_texts[2])\n",
    "lda[unseen_doc] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "chinese-wings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_0: компания год топливо поверхность который турецкий издание\n",
      "topic_1: рынок рост млн год объём доллар составить\n",
      "topic_2: рубль год проект санкция закон правительство nn\n",
      "topic_3: год который это исследование научный первый цена\n",
      "topic_4: это россия страна который сша президент год\n",
      "topic_5: форум писать связанный музыка бюро негативно ким\n",
      "topic_6: это год который свой весь человек жизнь\n",
      "topic_7: женщина золото женский профессия ми уральский мужчина\n",
      "topic_8: земля гражданин температура запуск космос участок площадь\n",
      "topic_9: газ это говорить всё мочь the газета\n",
      "topic_10: год это который россия ребёнок система фонд\n",
      "topic_11: двигатель это воздух день погода вирус дождь\n",
      "topic_12: энергия журнал испытание влиять общество ск это\n",
      "topic_13: ракета пенсия рейс лаборатория китай захватить сша\n",
      "topic_14: погибнуть район армия результат земля авария километр\n",
      "topic_15: российский украина станция россия экипаж граница год\n",
      "topic_16: восток характерный полоса диапазон держаться фаза игнорировать\n",
      "topic_17: фонд украина законодательство сектор кожа следствие украинский\n",
      "topic_18: экономика снижение риск год прогноз ставка снизить\n",
      "topic_19: обнаружить это который причина смерть мочь квартира\n",
      "topic_20: мозг египет фотография тверской король елизавета литва\n",
      "topic_21: военный северный боевой космонавт оборона сила устойчивый\n",
      "topic_22: банк который это nn болезнь всё россия\n",
      "topic_23: человек который год сотрудник тело мужчина операция\n",
      "topic_24: суд который статья дело это свой выяснить\n"
     ]
    }
   ],
   "source": [
    "x=lda.show_topics(num_topics=25, num_words=7,formatted=False)\n",
    "topics_words = [(tp[0], [wd[0] for wd in tp[1]]) for tp in x]\n",
    "\n",
    "#Below Code Prints Only Words \n",
    "for topic,words in topics_words:\n",
    "    print(\"topic_{}: \".format(topic)+\" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "miniature-enterprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lda_vector(text):\n",
    "    unseen_doc = common_dictionary.doc2bow(text)\n",
    "    lda_tuple = lda[unseen_doc]\n",
    "    not_null_topics = dict(zip([i[0] for i in lda_tuple], [i[1] for i in lda_tuple]))\n",
    "\n",
    "    output_vector = []\n",
    "    for i in range(25):\n",
    "        if i not in not_null_topics:\n",
    "            output_vector.append(0)\n",
    "        else:\n",
    "            output_vector.append(not_null_topics[i])\n",
    "    return np.array(output_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cooperative-observer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_15</th>\n",
       "      <th>topic_16</th>\n",
       "      <th>topic_17</th>\n",
       "      <th>topic_18</th>\n",
       "      <th>topic_19</th>\n",
       "      <th>topic_20</th>\n",
       "      <th>topic_21</th>\n",
       "      <th>topic_22</th>\n",
       "      <th>topic_23</th>\n",
       "      <th>topic_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.803771</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.429058</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.273001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.116974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.217399</td>\n",
       "      <td>0.100999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.372170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098963</td>\n",
       "      <td>0.108483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.163787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082946</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id  topic_0   topic_1  topic_2   topic_3   topic_4  topic_5   topic_6  \\\n",
       "0       6      0.0  0.000000      0.0  0.000000  0.120899      0.0  0.000000   \n",
       "1    4896      0.0  0.000000      0.0  0.000000  0.000000      0.0  0.000000   \n",
       "2    4897      0.0  0.000000      0.0  0.273001  0.000000      0.0  0.000000   \n",
       "3    4898      0.0  0.029171      0.0  0.000000  0.000000      0.0  0.217399   \n",
       "4    4899      0.0  0.000000      0.0  0.000000  0.372170      0.0  0.000000   \n",
       "\n",
       "    topic_7   topic_8  ...  topic_15  topic_16  topic_17  topic_18  topic_19  \\\n",
       "0  0.067246  0.000000  ...       0.0       0.0  0.000000       0.0  0.000000   \n",
       "1  0.257865  0.000000  ...       0.0       0.0  0.000000       0.0  0.000000   \n",
       "2  0.272461  0.000000  ...       0.0       0.0  0.000000       0.0  0.116974   \n",
       "3  0.100999  0.000000  ...       0.0       0.0  0.000000       0.0  0.000000   \n",
       "4  0.098963  0.108483  ...       0.0       0.0  0.163787       0.0  0.000000   \n",
       "\n",
       "   topic_20  topic_21  topic_22  topic_23  topic_24  \n",
       "0       0.0       0.0  0.803771  0.000000       0.0  \n",
       "1       0.0       0.0  0.000000  0.429058       0.0  \n",
       "2       0.0       0.0  0.000000  0.000000       0.0  \n",
       "3       0.0       0.0  0.057794  0.000000       0.0  \n",
       "4       0.0       0.0  0.082946  0.000000       0.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_matrix = pd.DataFrame([get_lda_vector(text) for text in news['title'].values])\n",
    "topic_matrix.columns = ['topic_{}'.format(i) for i in range(25)]\n",
    "topic_matrix['doc_id'] = news['doc_id'].values\n",
    "topic_matrix = topic_matrix[['doc_id']+['topic_{}'.format(i) for i in range(25)]]\n",
    "topic_matrix.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "interim-refrigerator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08438673, 0.        , 0.10556173, 0.13255735, 0.19691202,\n",
       "       0.        , 0.21326303, 0.        , 0.        , 0.06475788,\n",
       "       0.        , 0.        , 0.        , 0.02076281, 0.        ,\n",
       "       0.06408942, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.10798933])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_dict = dict(zip(topic_matrix['doc_id'].values, topic_matrix[['topic_{}'.format(i) for i in range(25)]].values))\n",
    "doc_dict[293622]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delayed-filing",
   "metadata": {},
   "source": [
    "## Модифицировать код функции get_user_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-reaction",
   "metadata": {},
   "source": [
    "Модифицировать код функции get_user_embedding таким образом, чтобы считалось не среднее (как в примере np.mean), а медиана. Применить такое преобразование к данным, обучить модель прогнозирования оттока и посчитать метрики качества и сохранить их: roc auc, precision/recall/f_score (для 3 последних - подобрать оптимальный порог с помощью precision_recall_curve, как это делалось на уроке)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "wrapped-royalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_articles_list = users['articles'].iloc[33]\n",
    "\n",
    "def get_user_embedding(user_articles_list, metric=np.mean):\n",
    "    user_articles_list = eval(user_articles_list)\n",
    "    user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
    "    user_vector = metric(user_vector, 0)\n",
    "    return user_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "sporting-pencil",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.05921824, 0.        , 0.2773228 ,\n",
       "       0.        , 0.05407586, 0.        , 0.        , 0.        ,\n",
       "       0.05580631, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.01392017, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.01072808])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_user_embedding(user_articles_list, np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "lonely-talent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция расчета метрик\n",
    "def get_metrics(metric):\n",
    "    user_embeddings = pd.DataFrame([i for i in users['articles'].apply(lambda x: get_user_embedding(x, metric), 1)])\n",
    "    user_embeddings.columns = [f'topic_{i}' for i in range(25)]\n",
    "    user_embeddings['uid'] = users['uid'].values\n",
    "    user_embeddings = user_embeddings[['uid']+[f'topic_{i}' for i in range(25)]]\n",
    "    X = pd.merge(user_embeddings, target, 'left')\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X[[f'topic_{i}' for i in range(25)]], \n",
    "                                                        X['churn'], shuffle=True, train_size=0.7, random_state=42)\n",
    "\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(X_train, y_train)\n",
    "    preds = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, preds)\n",
    "    fscore = (2 * precision * recall) / (precision + recall)\n",
    "    roc_auc = roc_auc_score(y_test, preds)\n",
    "    ix = np.argmax(fscore)\n",
    "    \n",
    "    return roc_auc, precision[ix], recall[ix], fscore[ix]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-pennsylvania",
   "metadata": {},
   "source": [
    "**mean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "undefined-sunset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc = 0.923, precision = 0.525, recall = 0.765, fscore = 0.623\n"
     ]
    }
   ],
   "source": [
    "m = list(get_metrics(np.mean))\n",
    "print(f'roc_auc = {m[0]:.3f}, precision = {m[1]:.3f}, recall = {m[2]:.3f}, fscore = {m[3]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-narrow",
   "metadata": {},
   "source": [
    "**median**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "smaller-belarus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc = 0.943, precision = 0.611, recall = 0.746, fscore = 0.672\n"
     ]
    }
   ],
   "source": [
    "m = list(get_metrics(np.median))\n",
    "print(f'roc_auc = {m[0]:.3f}, precision = {m[1]:.3f}, recall = {m[2]:.3f}, fscore = {m[3]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strong-texas",
   "metadata": {},
   "source": [
    "## Метрика max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-liability",
   "metadata": {},
   "source": [
    "Повторить п.2, но используя уже не медиану, а max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-romania",
   "metadata": {},
   "source": [
    "**max**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "adequate-average",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc = 0.975, precision = 0.738, recall = 0.870, fscore = 0.798\n"
     ]
    }
   ],
   "source": [
    "m = list(get_metrics(np.max))\n",
    "print(f'roc_auc = {m[0]:.3f}, precision = {m[1]:.3f}, recall = {m[2]:.3f}, fscore = {m[3]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upset-accountability",
   "metadata": {},
   "source": [
    "## Таблица метрик"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-photography",
   "metadata": {},
   "source": [
    "Сформировать на выходе единую таблицу, сравнивающую качество 3 разных метода получения эмбедингов пользователей: mean, median, max, idf_mean по метрикам roc_auc, precision, recall, f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "hourly-subject",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {'mean': np.mean, 'median': np.median, 'max': np.max}\n",
    "info = pd.DataFrame(columns=metrics.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "running-escape",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean <function mean at 0x00000174FD3A9B88>\n",
      "median <function median at 0x00000174FD506828>\n",
      "max <function amax at 0x00000174FD397948>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.922987</td>\n",
       "      <td>0.943186</td>\n",
       "      <td>0.974805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.524554</td>\n",
       "      <td>0.610667</td>\n",
       "      <td>0.737569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.765472</td>\n",
       "      <td>0.745928</td>\n",
       "      <td>0.869707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fscore</th>\n",
       "      <td>0.622517</td>\n",
       "      <td>0.671554</td>\n",
       "      <td>0.798206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean    median       max\n",
       "roc_auc    0.922987  0.943186  0.974805\n",
       "precision  0.524554  0.610667  0.737569\n",
       "recall     0.765472  0.745928  0.869707\n",
       "fscore     0.622517  0.671554  0.798206"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for metric, value in metrics.items():\n",
    "    print(metric, value)\n",
    "    roc_auc, precision, recall, fscore = get_metrics(value)\n",
    "    info.loc[f'roc_auc', metric] = roc_auc\n",
    "    info.loc[f'precision', metric] = precision\n",
    "    info.loc[f'recall', metric] = recall\n",
    "    info.loc[f'fscore', metric] = fscore\n",
    "    \n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-journey",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
