{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ДЗ 6. Двухуровневые модели рекомендаций\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Для работы с матрицами\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Матричная факторизация\n",
    "from implicit import als\n",
    "\n",
    "# Модель второго уровня\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join(os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Написанные нами функции\n",
    "from src.metrics import precision_at_k, recall_at_k\n",
    "from src.utils import prefilter_items\n",
    "from src.recommenders import MainRecommender\n",
    "\n",
    "# Матричная факторизация\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.nearest_neighbours import ItemItemRecommender  # нужен для одного трюка\n",
    "from implicit.nearest_neighbours import bm25_weight, tfidf_weight\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>basket_id</th>\n",
       "      <th>day</th>\n",
       "      <th>item_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>sales_value</th>\n",
       "      <th>store_id</th>\n",
       "      <th>retail_disc</th>\n",
       "      <th>trans_time</th>\n",
       "      <th>week_no</th>\n",
       "      <th>coupon_disc</th>\n",
       "      <th>coupon_match_disc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1004906</td>\n",
       "      <td>1</td>\n",
       "      <td>1.39</td>\n",
       "      <td>364</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1033142</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id    basket_id  day  item_id  quantity  sales_value  store_id  \\\n",
       "0     2375  26984851472    1  1004906         1         1.39       364   \n",
       "1     2375  26984851472    1  1033142         1         0.82       364   \n",
       "\n",
       "   retail_disc  trans_time  week_no  coupon_disc  coupon_match_disc  \n",
       "0         -0.6        1631        1          0.0                0.0  \n",
       "1          0.0        1631        1          0.0                0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/retail_train.csv')\n",
    "item_features = pd.read_csv('data/product.csv')\n",
    "user_features = pd.read_csv('data/hh_demographic.csv')\n",
    "\n",
    "# column processing\n",
    "item_features.columns = [col.lower() for col in item_features.columns]\n",
    "user_features.columns = [col.lower() for col in user_features.columns]\n",
    "\n",
    "item_features.rename(columns={'product_id': 'item_id'}, inplace=True)\n",
    "user_features.rename(columns={'household_key': 'user_id'}, inplace=True)\n",
    "\n",
    "\n",
    "# Важна схема обучения и валидации!\n",
    "# -- давние покупки -- | -- 6 недель -- | -- 3 недель -- \n",
    "# подобрать размер 2-ого датасета (6 недель) --> learning curve (зависимость метрики recall@k от размера датасета)\n",
    "val_lvl_1_size_weeks = 6\n",
    "val_lvl_2_size_weeks = 3\n",
    "\n",
    "data_train_lvl_1 = data[data['week_no'] < data['week_no'].max() - (val_lvl_1_size_weeks + val_lvl_2_size_weeks)]\n",
    "data_val_lvl_1 = data[(data['week_no'] >= data['week_no'].max() - (val_lvl_1_size_weeks + val_lvl_2_size_weeks)) &\n",
    "                      (data['week_no'] < data['week_no'].max() - (val_lvl_2_size_weeks))]\n",
    "\n",
    "data_train_lvl_2 = data_val_lvl_1.copy()  # Для наглядности. Далее мы добавим изменения, и они будут отличаться\n",
    "data_val_lvl_2 = data[data['week_no'] >= data['week_no'].max() - val_lvl_2_size_weeks]\n",
    "\n",
    "data_train_lvl_1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decreased # items from 83685 to 5001\n",
      "Decreased # users from 2498 to 2495\n"
     ]
    }
   ],
   "source": [
    "n_items_before = data_train_lvl_1['item_id'].nunique()\n",
    "n_user_before = data_train_lvl_1['user_id'].nunique()\n",
    "\n",
    "#параметры функции могут отличаться\n",
    "data_train_lvl_1 = prefilter_items(data_train_lvl_1, take_n_popular=5000, item_features=item_features)\n",
    "\n",
    "n_items_after = data_train_lvl_1['item_id'].nunique()\n",
    "n_user_after = data_train_lvl_1['user_id'].nunique()\n",
    "print('Decreased # items from {} to {}'.format(n_items_before, n_items_after))\n",
    "print('Decreased # users from {} to {}'.format(n_user_before, n_user_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f46199969854ce8bf92d2b0d388d291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81a75f1e256e44fb89ee1bf1865419a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5001.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recommender = MainRecommender(data_train_lvl_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[899624, 871756, 1044078, 1106523, 844179]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender.get_als_recommendations(2375, N=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[948640, 918046, 847962, 907099, 873980]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender.get_own_recommendations(2375, N=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1046545, 1044078, 844179, 1078652, 15778319]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender.get_similar_items_recommendation(2375, N=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1097398, 1096573, 835351, 861494, 821741]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender.get_similar_users_recommendation(2375, N=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1\n",
    "\n",
    "A) Попробуйте различные варианты генерации кандидатов. Какие из них дают наибольший recall@k ?\n",
    "- Пока пробуем отобрать 50 кандидатов (k=50)\n",
    "- Качество измеряем на data_val_lvl_1: следующие 6 недель после трейна\n",
    "\n",
    "Дают ли own recommendtions + top-popular лучший recall?  \n",
    "\n",
    "B)* Как зависит recall@k от k? Постройте для одной схемы генерации кандидатов эту зависимость для k = {20, 50, 100, 200, 500}  \n",
    "C)* Исходя из прошлого вопроса, как вы думаете, какое значение k является наиболее разумным?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[853529, 865456, 867607, 872137, 874905, 87524...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[15830248, 838136, 839656, 861272, 866211, 870...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>[883932, 970760, 1035676, 1055863, 1097610, 67...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                             actual\n",
       "0        1  [853529, 865456, 867607, 872137, 874905, 87524...\n",
       "1        2  [15830248, 838136, 839656, 861272, 866211, 870...\n",
       "2        4  [883932, 970760, 1035676, 1055863, 1097610, 67..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_lvl_1 = data_val_lvl_1.groupby('user_id')['item_id'].unique().reset_index()\n",
    "result_lvl_1.columns=['user_id', 'actual']\n",
    "result_lvl_1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([296, 1813, 1984], 3, 2151)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_train = data_train_lvl_1['user_id'].tolist()\n",
    "users_valid = result_lvl_1['user_id'].tolist()\n",
    "new_users = list(set(users_valid) - set(users_train))\n",
    "all_users = list(set(users_valid) & set(users_train))\n",
    "\n",
    "result_lvl_1 = result_lvl_1[~result_lvl_1['user_id'].isin(new_users)]\n",
    "\n",
    "new_users, len(new_users), len(all_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012717849470524154"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_lvl_1['als'] = result_lvl_1['user_id'].apply(lambda x: recommender.get_als_recommendations(x, N))\n",
    "result_lvl_1.apply(lambda row: recall_at_k(row['als'], row['actual']), axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.018201887674891032"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_lvl_1['own_recommendations'] = \\\n",
    "            result_lvl_1['user_id'].apply(lambda x: recommender.get_own_recommendations(x, N))\n",
    "result_lvl_1.apply(lambda row: recall_at_k(row['own_recommendations'], row['actual']), axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006493707877464577"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_lvl_1['similar_items_recommendation'] = \\\n",
    "            result_lvl_1['user_id'].apply(lambda x: recommender.get_similar_items_recommendation(x, N))\n",
    "result_lvl_1.apply(lambda row: recall_at_k(row['similar_items_recommendation'], row['actual']), axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0017793690086107894"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_lvl_1['similar_users_recommendation'] = \\\n",
    "            result_lvl_1['user_id'].apply(lambda x: recommender.get_similar_users_recommendation(x, N))\n",
    "result_lvl_1.apply(lambda row: recall_at_k(row['similar_users_recommendation'], row['actual']), axis=1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: наилучший результат дают собственные покупки, что неудивительно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2.\n",
    "\n",
    "Обучите модель 2-ого уровня, при этом:  \n",
    "\n",
    "    - Добавьте минимум по 2 фичи для юзера, товара и пары юзер-товар  \n",
    "    - Измерьте отдельно precision@5 модели 1-ого уровня и двухуровневой модели на data_val_lvl_2  \n",
    "    - Вырос ли precision@5 при использовании двухуровневой модели?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем новые фичи\n",
    "\n",
    "def new_user_features(data, user_features):\n",
    "    new_user_features = user_features.merge(data, on='user_id', how='left')\n",
    "    \n",
    "    # Чек\n",
    "    basket = new_user_features.groupby(['user_id'])['sales_value'].sum().reset_index()\n",
    "    baskets_qnt = new_user_features.groupby('user_id')['basket_id'].count().reset_index()\n",
    "    baskets_qnt.rename(columns={'basket_id': 'baskets_qnt'}, inplace=True)\n",
    "    \n",
    "    # Средний недельный чек\n",
    "    average_basket = basket.merge(baskets_qnt)\n",
    "    average_basket['average_basket'] = average_basket.sales_value / average_basket.baskets_qnt\n",
    "    average_basket['sum_per_week'] = average_basket.sales_value / new_user_features.week_no.nunique()\n",
    "    average_basket = average_basket.drop(['sales_value', 'baskets_qnt'], axis=1)\n",
    "    user_features = user_features.merge(average_basket)\n",
    "\n",
    "    return user_features\n",
    "\n",
    "\n",
    "def new_item_features(data, item_features):\n",
    "    new_item_features = item_features.merge(data, on='item_id', how='left')\n",
    "    \n",
    "    # Цена\n",
    "    price = new_item_features.groupby('item_id')['sales_value'].sum() \\\n",
    "                            / new_item_features.groupby('item_id')['quantity'].sum()\n",
    "    price = price.groupby('item_id').mean().reset_index()\n",
    "    price.columns = ['item_id', 'price']\n",
    "    price['price'].fillna(0, inplace= True)\n",
    "    \n",
    "    # Количество продаж и среднее количество продаж товара\n",
    "    item_qnt = new_item_features.groupby(['item_id'])['quantity'].count().reset_index()\n",
    "    item_qnt.rename(columns={'quantity': 'quantity_of_sales'}, inplace=True)\n",
    "    item_qnt['quantity_of_sales_per_week'] = \\\n",
    "                item_qnt['quantity_of_sales'] / new_item_features['week_no'].nunique()\n",
    "    item_features = item_features.merge(item_qnt, on='item_id')\n",
    "    \n",
    "    return item_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предобработка данных\n",
    "\n",
    "def train_test_preprocessing(data):    \n",
    "    users_lvl_2 = pd.DataFrame(data['user_id'].unique())\n",
    "    users_lvl_2.columns = ['user_id']\n",
    "\n",
    "    train_users = data_train_lvl_1['user_id'].unique()\n",
    "    train_users.shape\n",
    "\n",
    "    users_lvl_2 = users_lvl_2[users_lvl_2['user_id'].isin(train_users)]\n",
    "    users_lvl_2_ = users_lvl_2.copy()\n",
    "    users_lvl_2['candidates'] = users_lvl_2['user_id'].apply(lambda x: recommender.get_own_recommendations(x, N=50))\n",
    "    \n",
    "    s = users_lvl_2.apply(lambda x: pd.Series(x['candidates']), axis=1).stack().reset_index(level=1, drop=True)\n",
    "    s.name = 'item_id'\n",
    "\n",
    "    users_lvl_2 = users_lvl_2.drop('candidates', axis=1).join(s)\n",
    "    \n",
    "    users_lvl_2['flag'] = 1\n",
    "\n",
    "    targets_lvl_2 = data[['user_id', 'item_id']].copy()\n",
    "    targets_lvl_2.head(2)\n",
    "\n",
    "    targets_lvl_2['target'] = 1  \n",
    "\n",
    "    targets_lvl_2 = users_lvl_2.merge(targets_lvl_2, on=['user_id', 'item_id'], how='left')\n",
    "\n",
    "    targets_lvl_2['target'].fillna(0, inplace= True)\n",
    "    targets_lvl_2.drop('flag', axis=1, inplace=True)\n",
    "\n",
    "    targets_lvl_2 = targets_lvl_2.merge(item_features, on='item_id', how='left')\n",
    "    targets_lvl_2 = targets_lvl_2.merge(user_features, on='user_id', how='left')\n",
    "\n",
    "    X = targets_lvl_2.drop('target', axis=1)\n",
    "    y = targets_lvl_2[['target']]\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем рекомендации\n",
    "\n",
    "def get_final_recomendation(X_test, test_preds_proba, data_val_lvl_2):\n",
    "    X_test['predict_proba'] = test_preds_proba\n",
    "\n",
    "    X_test.sort_values(['user_id', 'predict_proba'], ascending=False, inplace=True)\n",
    "\n",
    "    result = X_test.groupby('user_id').head(5)\n",
    "\n",
    "    recs = result.groupby('user_id')['item_id']\n",
    "    recomendations = []\n",
    "    for user, preds in recs:\n",
    "        recomendations.append({'user_id': user, 'recomendations': preds.tolist()})\n",
    "\n",
    "    recomendations = pd.DataFrame(recomendations)\n",
    "\n",
    "    result_lvl_2 = data_val_lvl_2.groupby('user_id')['item_id'].unique().reset_index()\n",
    "    result_lvl_2.columns=['user_id', 'actual']\n",
    "\n",
    "    result_lvl_2 = result_lvl_2.merge(recomendations)\n",
    "    \n",
    "    return result_lvl_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем новые фичи\n",
    "item_features = new_item_features(data_train_lvl_2, item_features)\n",
    "user_features = new_user_features(data_train_lvl_2, user_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предобработка данных\n",
    "X_train, y_train = train_test_preprocessing(data_train_lvl_2)\n",
    "cat_feats = X_train.columns[2:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[cat_feats] = X_train[cat_feats].astype('category')\n",
    "X_test, y_test = train_test_preprocessing(data_val_lvl_2)\n",
    "X_test[cat_feats] = X_test[cat_feats].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.35878407, 0.35878407, 0.02560159, ..., 0.03243339, 0.00920873,\n",
       "       0.04036886])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучаем модель\n",
    "lgb = LGBMClassifier(objective='binary', \n",
    "                     max_depth=7, \n",
    "                     categorical_column=cat_feats)\n",
    "\n",
    "lgb.fit(X_train, y_train)\n",
    "\n",
    "test_preds_proba = lgb.predict_proba(X_test)[:, 1]\n",
    "test_preds_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем рекомендации\n",
    "result_lvl_2 = get_final_recomendation(X_test, test_preds_proba, data_val_lvl_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14735294117646902"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Считаем метрику\n",
    "result_lvl_2.apply(lambda row: precision_at_k(row['recomendations'], row['actual']), axis=1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: Модель 2-го уровня не дала существенного прироста, требуется уделить больше внимания подготовке данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
